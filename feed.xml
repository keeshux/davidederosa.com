<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://davidederosa.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://davidederosa.com/" rel="alternate" type="text/html" /><updated>2025-04-24T17:18:01+02:00</updated><id>https://davidederosa.com/feed.xml</id><title type="html">Davide De Rosa</title><subtitle>I make software. I look around me.</subtitle><author><name>Davide De Rosa</name></author><entry><title type="html">Scripting and open-source adoption</title><link href="https://davidederosa.com/2025/04/scripting-and-open-source-adoption/" rel="alternate" type="text/html" title="Scripting and open-source adoption" /><published>2025-04-24T00:00:00+02:00</published><updated>2025-04-24T00:00:00+02:00</updated><id>https://davidederosa.com/2025/04/scripting-and-open-source-adoption</id><content type="html" xml:base="https://davidederosa.com/2025/04/scripting-and-open-source-adoption/"><![CDATA[<p>Recently, I stumbled upon an <a href="https://www.youtube.com/watch?v=p0Q3oDY9A5s">old video by ThePrimeagen</a> where he claimed he’d quit using Vim for good after its major update.</p>

<p>For those who don’t know, <a href="https://www.vim.org/">Vim</a> is a <em>ubiquitous</em> text editor, especially popular among avid terminal-oriented users. It is a legendary software, but it has a steep learning curve, to the point that “quitting Vim” <a href="https://stackoverflow.com/questions/11828270/how-do-i-exit-vim">has become a meme</a> for being notoriously unintuitive.</p>

<p><a href="https://twitch.tv/theprimeagen">ThePrimeagen</a> is a prominent Twitch streamer, and a stark advocate of <a href="https://neovim.io/">Neovim</a>, a fork of the original Vim editor. In his video, he makes a solid point about the stubbornness of Vim maintainers to stick with a custom scripting language. On the other hand, Neovim, promotes the well-known <a href="https://www.lua.org/">Lua</a> language for its powerful plugin system. This alone determined his final choice to stick with Neovim, and as of 2025, I doubt he has changed his mind.</p>

<h2 id="the-delusion-behind-open-source">The delusion behind open-source</h2>

<p>This story is somewhat related to what I’m trying now that I work full-time on <a href="https://passepartoutvpn.app">Passepartout</a>. Passepartout is an open-source project in that its code is public, but there are almost no code contributions, just issues. There are good reasons behind this.</p>

<p>Many of those who create some sort of open-source software think that it must be interesting by default, just because it’s open and available for free. Rarely will they realize that <em>popuplar</em> free software not only is popular <em>for being free</em>, so they live the delusion that the open-source model “doesn’t work”.</p>

<p>For example, pick any GNU tool (grep, sed, make, …) or even Linux. They became popular because they were <em>useful</em>. Being free and <em>understandable</em> software made them thrive through public contributions, but this was never the first step.</p>

<p>The interest in contributing to an open-source project is determined by multiple factors, in order of importance:</p>

<ol>
  <li>Goals</li>
  <li>Well-written documentation and directions</li>
  <li>Welcoming community</li>
  <li>Technical stack</li>
  <li>Stable software architecture</li>
</ol>

<p>Now, observe how any well-known free software meets 1-5 in that order.</p>

<h2 id="vim-and-the-self-conscious-tech">Vim and the self-conscious tech</h2>

<p>Given that both Vim and Neovim are amazing and well-documented products, their tech paths reconnect with the initial backstory.</p>

<p>Lua makes Neovim <em>infinitely</em> more attractive than Vim when it comes to adoption and open-source, and the choice of Vimscript over Lua may even determine the death of Vim in the long run. I don’t know the “drama” that resulted in the fork of Neovim, but I wouldn’t exclude that Vim took its relevance for granted just for being the OG of the two. In fact, I don’t think that Vim today can claim being cooler than Neovim other than for being the original one.</p>

<p>Even if a software is well-crafted, it’s evident that a Pascal application will only attract a handful of developers, whereas JavaScript would open up to the entire globe, and the same applies to Vimscript versus Lua. If your software is written for yourself and requires developers to learn a new technology to contribute, either it is <em>the ultimate cool</em>, or you might well end up yelling at your echo chamber.</p>

<h2 id="passepartout-adds-a-javascript-api">Passepartout adds a JavaScript API</h2>

<p>While I invest a lot in making the software architecture as accessible as I can, I haven’t spent as much time in documenting <em>how</em> to start contributing to the codebase. I know myself how intimidating it is to submit a PR to someone else’s repository, so it’s crucial that we, the maintainers, provide a viable entry point to those willing to collaborate. A welcoming, non-judging community also reduces the friction of the first public contribution.</p>

<p>One part that I’ve always found potentially accessible was the Providers API, which is how Passepartout auto-compiles VPN configurations for a plethora of provider servers. Nevertheless, no one ever contributed a single provider, and no wonder: providers were generated in CI with a convoluted set of undocumented Ruby scripts. Who on Earth would want to touch that mess?</p>

<p>When I found out about <a href="https://developer.apple.com/documentation/javascriptcore">JavaScriptCore</a> to solve a different problem, I suddenly realized how scripting could be a lower barrier to enter the Passepartout codebase, as there are way more JavaScript than Swift developers out there.</p>

<p>With the help of AI, I rapidly converted the old Ruby legacy to a brand new <a href="https://github.com/passepartoutvpn/api-source">Node.js implementation</a> that most developers would find easy to understand, develop, and test without even installing the app. Then I started documenting <a href="https://github.com/passepartoutvpn/api-source?tab=readme-ov-file#new-providers">how to submit a provider</a> step by step. This doesn’t imply that people will start adding new providers today, but offering accessible tools and documentation is a <em>strict</em> requirement for that to happen.</p>

<h2 id="conclusions">Conclusions</h2>

<p>Open-source success isn’t about being free, it’s about being accessible. Tools like Neovim thrive because they choose approachable technologies like Lua, making contributions easier. Similarly, by adopting JavaScript for scripting, Passepartout lowers its barrier to entry and opens the door to wider community involvement. If you want contributors, you must meet them where they are.</p>]]></content><author><name>Davide De Rosa</name></author><category term="development" /><category term="lua" /><category term="javascript" /><category term="vim" /><category term="neovim" /><category term="open-source" /><summary type="html"><![CDATA[Recently, I stumbled upon an old video by ThePrimeagen where he claimed he’d quit using Vim for good after its major update. For those who don’t know, Vim is a ubiquitous text editor, especially popular among avid terminal-oriented users. It is a legendary software, but it has a steep learning curve, to the point that “quitting Vim” has become a meme for being notoriously unintuitive. ThePrimeagen is a prominent Twitch streamer, and a stark advocate of Neovim, a fork of the original Vim editor. In his video, he makes a solid point about the stubbornness of Vim maintainers to stick with a custom scripting language. On the other hand, Neovim, promotes the well-known Lua language for its powerful plugin system. This alone determined his final choice to stick with Neovim, and as of 2025, I doubt he has changed his mind. The delusion behind open-source This story is somewhat related to what I’m trying now that I work full-time on Passepartout. Passepartout is an open-source project in that its code is public, but there are almost no code contributions, just issues. There are good reasons behind this. Many of those who create some sort of open-source software think that it must be interesting by default, just because it’s open and available for free. Rarely will they realize that popuplar free software not only is popular for being free, so they live the delusion that the open-source model “doesn’t work”. For example, pick any GNU tool (grep, sed, make, …) or even Linux. They became popular because they were useful. Being free and understandable software made them thrive through public contributions, but this was never the first step. The interest in contributing to an open-source project is determined by multiple factors, in order of importance: Goals Well-written documentation and directions Welcoming community Technical stack Stable software architecture Now, observe how any well-known free software meets 1-5 in that order. Vim and the self-conscious tech Given that both Vim and Neovim are amazing and well-documented products, their tech paths reconnect with the initial backstory. Lua makes Neovim infinitely more attractive than Vim when it comes to adoption and open-source, and the choice of Vimscript over Lua may even determine the death of Vim in the long run. I don’t know the “drama” that resulted in the fork of Neovim, but I wouldn’t exclude that Vim took its relevance for granted just for being the OG of the two. In fact, I don’t think that Vim today can claim being cooler than Neovim other than for being the original one. Even if a software is well-crafted, it’s evident that a Pascal application will only attract a handful of developers, whereas JavaScript would open up to the entire globe, and the same applies to Vimscript versus Lua. If your software is written for yourself and requires developers to learn a new technology to contribute, either it is the ultimate cool, or you might well end up yelling at your echo chamber. Passepartout adds a JavaScript API While I invest a lot in making the software architecture as accessible as I can, I haven’t spent as much time in documenting how to start contributing to the codebase. I know myself how intimidating it is to submit a PR to someone else’s repository, so it’s crucial that we, the maintainers, provide a viable entry point to those willing to collaborate. A welcoming, non-judging community also reduces the friction of the first public contribution. One part that I’ve always found potentially accessible was the Providers API, which is how Passepartout auto-compiles VPN configurations for a plethora of provider servers. Nevertheless, no one ever contributed a single provider, and no wonder: providers were generated in CI with a convoluted set of undocumented Ruby scripts. Who on Earth would want to touch that mess? When I found out about JavaScriptCore to solve a different problem, I suddenly realized how scripting could be a lower barrier to enter the Passepartout codebase, as there are way more JavaScript than Swift developers out there. With the help of AI, I rapidly converted the old Ruby legacy to a brand new Node.js implementation that most developers would find easy to understand, develop, and test without even installing the app. Then I started documenting how to submit a provider step by step. This doesn’t imply that people will start adding new providers today, but offering accessible tools and documentation is a strict requirement for that to happen. Conclusions Open-source success isn’t about being free, it’s about being accessible. Tools like Neovim thrive because they choose approachable technologies like Lua, making contributions easier. Similarly, by adopting JavaScript for scripting, Passepartout lowers its barrier to entry and opens the door to wider community involvement. If you want contributors, you must meet them where they are.]]></summary></entry><entry><title type="html">Cross-platform Swift: Combine</title><link href="https://davidederosa.com/cross-platform-swift/combine/" rel="alternate" type="text/html" title="Cross-platform Swift: Combine" /><published>2025-04-23T00:00:00+02:00</published><updated>2025-04-23T00:00:00+02:00</updated><id>https://davidederosa.com/cross-platform-swift/cross-platform-swift-combine</id><content type="html" xml:base="https://davidederosa.com/cross-platform-swift/combine/"><![CDATA[<p>The very first goal of porting may sound simple: a successful build. Once you manage to just compile your package, the worst is definitely behind you.</p>

<p>Keep in mind that this is not a series about how to port Apple frameworks or SwiftUI to other platforms, it’s about the bare Swift language. I want to show you how Xcode may trick you into thinking that some patterns are a key part of Swift, whereas they should be avoided if you plan to leave the Apple ecosystem at some point.</p>

<p>Today, I’ll talk about a kind of infamous framework for Swift developers: <em>Combine</em>.</p>

<h2 id="combine-is-unofficially-obsolete">Combine is unofficially obsolete</h2>

<p>When the compiler suddenly stopped at some occurrence of <code class="language-plaintext highlighter-rouge">import Combine</code>, I was beaten. Combine has been a fundamental piece of reactive programming for the last 5+ years, and any recent Swift codebase uses Combine to some extent. The scary question was: to what extent was I using it?</p>

<p>Let me digress a moment. There is a big problem with Combine, and it’s not about the developers using it. Apple is well-known for disrupting its own frameworks regardless of any backward-compatibility, and Combine is one of those examples where Apple took a different turn without offering a full replacement. Initially, it seemed that SwiftUI was all about Combine, but the introduction of Concurrency made the poor framework an outcast. Unsurprisingly, <code class="language-plaintext highlighter-rouge">ObservableObject</code> and <code class="language-plaintext highlighter-rouge">@Published</code> are also unavailable outside Apple Swift, but if you’ve been a diligent programmer, you’ve probably learned that those constructs only make sense with SwiftUI.</p>

<p>The fact that Combine has never been integrated into the Swift language, reveals that Concurrency is how Swift (and Apple) wants you to perform asynchronous programming from now on. Does Swift natively offer a substitute for the long list of Combine operators? Hell, no, and that’s why people still use Combine.</p>

<p>Back to my question. Luckily, my use of Combine in Partout was quite basic, except for one <code class="language-plaintext highlighter-rouge">.combineLatest3()</code> that was worth half the effort.</p>

<h2 id="porting-to-asyncsequence">Porting to AsyncSequence</h2>

<p>If you remember, the purpose of Combine is manipulating a sequence of asynchronous values. Swift offers implementations of <a href="https://developer.apple.com/documentation/swift/asyncsequence"><code class="language-plaintext highlighter-rouge">AsyncSequence</code></a> like <a href="https://developer.apple.com/documentation/swift/asyncstream"><code class="language-plaintext highlighter-rouge">AsyncStream</code></a> and <a href="https://developer.apple.com/documentation/swift/asyncthrowingstream"><code class="language-plaintext highlighter-rouge">AsyncThrowingStream</code></a> to accomplish the same in a linear fashion, typical of the async/await model.</p>

<p>What in Combine was:</p>

<div class="language-swift highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">subscription</span> <span class="o">=</span> <span class="nf">somePublisherOfStrings</span><span class="p">()</span> <span class="c1">// AnyPublisher&lt;String, Never&gt;</span>
    <span class="o">.</span><span class="nf">removeDuplicates</span><span class="p">()</span>
    <span class="o">.</span><span class="n">sink</span> <span class="p">{</span> <span class="p">[</span><span class="k">weak</span> <span class="k">self</span><span class="p">]</span> <span class="k">in</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">"String: </span><span class="se">\(</span><span class="nv">$0</span><span class="se">)</span><span class="s">"</span><span class="p">)</span>
    <span class="p">}</span>
</code></pre></div></div>

<p>becomes this with <code class="language-plaintext highlighter-rouge">AsyncStream</code>:</p>

<div class="language-swift highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">subscription</span> <span class="o">=</span> <span class="kt">Task</span> <span class="p">{</span> <span class="p">[</span><span class="k">weak</span> <span class="k">self</span><span class="p">]</span> <span class="k">in</span>
    <span class="k">var</span> <span class="nv">previous</span><span class="p">:</span> <span class="kt">String</span><span class="p">?</span>
    <span class="k">for</span> <span class="k">await</span> <span class="n">string</span> <span class="k">in</span> <span class="nf">someStreamOfStrings</span><span class="p">()</span> <span class="p">{</span> <span class="c1">// AsyncStream&lt;String&gt;</span>
        <span class="k">guard</span> <span class="n">string</span> <span class="o">!=</span> <span class="n">previous</span> <span class="k">else</span> <span class="p">{</span>
            <span class="k">continue</span>
        <span class="p">}</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">"String: </span><span class="se">\(</span><span class="nv">$0</span><span class="se">)</span><span class="s">"</span><span class="p">)</span>
        <span class="n">previous</span> <span class="o">=</span> <span class="n">string</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Now, a typical way to spawn Combine publishers is with <em>subjects</em> (<code class="language-plaintext highlighter-rouge">PassthroughSubject</code> and <code class="language-plaintext highlighter-rouge">CurrentValueSubject</code>), that are multicast emitters of values. Multiple programs can subscribe to a subject, listen to its sequence of values, and manipulate them before delivery with the rich offer of Combine operators. We lack such a counterpart in Swift, so I went to <a href="https://github.com/keeshux/subject-streams">roll out my own</a>.</p>

<p>My <a href="https://github.com/keeshux/subject-streams/blob/master/Sources/SubjectStreams/PassthroughStream.swift"><code class="language-plaintext highlighter-rouge">PassthroughStream</code></a> and <a href="https://github.com/keeshux/subject-streams/blob/master/Sources/SubjectStreams/CurrentValueStream.swift"><code class="language-plaintext highlighter-rouge">CurrentValueStream</code></a> implement a simple pub/sub pattern with <code class="language-plaintext highlighter-rouge">AsyncStream</code> and strict Swift 6.1 Concurrency. They have become the building blocks of all my asynchronous publishers in cross-platform Swift, and by keeping behavior and naming close to Combine (e.g. the <code class="language-plaintext highlighter-rouge">.send()</code> method), the refactoring was easier to manage.</p>

<p>Steps:</p>

<ul>
  <li>Replace Combine subjects with <a href="https://github.com/keeshux/subject-streams"><em>subject streams</em></a></li>
  <li>Return an <code class="language-plaintext highlighter-rouge">AsyncStream</code> from a subject with <code class="language-plaintext highlighter-rouge">.subscribe()</code></li>
  <li>Replace <code class="language-plaintext highlighter-rouge">AnyCancellable</code> with <code class="language-plaintext highlighter-rouge">Task</code> and <code class="language-plaintext highlighter-rouge">for [try] await</code> loops (<code class="language-plaintext highlighter-rouge">weak self</code> here)</li>
</ul>

<p>Before:</p>

<div class="language-swift highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">final</span> <span class="kd">class</span> <span class="kt">RandomGenerator</span> <span class="p">{</span>
    <span class="kd">private</span> <span class="k">let</span> <span class="nv">generator</span> <span class="o">=</span> <span class="kt">PassthroughSubject</span><span class="o">&lt;</span><span class="kt">Int</span><span class="p">,</span> <span class="kt">Never</span><span class="o">&gt;</span><span class="p">()</span>

    <span class="k">var</span> <span class="nv">publisher</span><span class="p">:</span> <span class="kt">AnyPublisher</span><span class="o">&lt;</span><span class="kt">Int</span><span class="p">,</span> <span class="kt">Never</span><span class="o">&gt;</span> <span class="p">{</span>
        <span class="n">generator</span><span class="o">.</span><span class="nf">eraseToAnyPublisher</span><span class="p">()</span>
    <span class="p">}</span>

    <span class="kd">func</span> <span class="nf">run</span><span class="p">()</span> <span class="p">{</span>
        <span class="n">generator</span><span class="o">.</span><span class="nf">send</span><span class="p">(</span><span class="o">.</span><span class="nf">random</span><span class="p">(</span><span class="nv">in</span><span class="p">:</span> <span class="mi">1</span><span class="o">...</span><span class="mi">1000</span><span class="p">))</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="o">...</span>

<span class="k">let</span> <span class="nv">prng</span> <span class="o">=</span> <span class="kt">RandomGenerator</span><span class="p">()</span>
<span class="k">var</span> <span class="nv">subscription</span> <span class="o">=</span> <span class="n">prng</span><span class="o">.</span><span class="n">publisher</span><span class="o">.</span><span class="n">sink</span> <span class="p">{</span> <span class="p">[</span><span class="k">weak</span> <span class="k">self</span><span class="p">]</span> <span class="n">value</span> <span class="k">in</span>
    <span class="o">...</span>
<span class="p">}</span>

</code></pre></div></div>

<p>After:</p>

<div class="language-swift highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">final</span> <span class="kd">class</span> <span class="kt">RandomGenerator</span> <span class="p">{</span>
    <span class="kd">private</span> <span class="k">let</span> <span class="nv">generator</span> <span class="o">=</span> <span class="kt">PassthroughStream</span><span class="o">&lt;</span><span class="kt">Int</span><span class="o">&gt;</span><span class="p">()</span>

    <span class="k">var</span> <span class="nv">publisher</span><span class="p">:</span> <span class="kt">AsyncStream</span><span class="o">&lt;</span><span class="kt">Int</span><span class="o">&gt;</span> <span class="p">{</span>
        <span class="n">generator</span><span class="o">.</span><span class="nf">subscribe</span><span class="p">()</span>
    <span class="p">}</span>

    <span class="kd">func</span> <span class="nf">run</span><span class="p">()</span> <span class="p">{</span>
        <span class="n">generator</span><span class="o">.</span><span class="nf">send</span><span class="p">(</span><span class="o">.</span><span class="nf">random</span><span class="p">(</span><span class="nv">in</span><span class="p">:</span> <span class="mi">1</span><span class="o">...</span><span class="mi">1000</span><span class="p">))</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="o">...</span>

<span class="k">let</span> <span class="nv">prng</span> <span class="o">=</span> <span class="kt">RandomGenerator</span><span class="p">()</span>
<span class="k">var</span> <span class="nv">subscription</span> <span class="o">=</span> <span class="kt">Task</span> <span class="p">{</span> <span class="p">[</span><span class="k">weak</span> <span class="k">self</span><span class="p">]</span> <span class="k">in</span>
    <span class="k">for</span> <span class="k">await</span> <span class="n">value</span> <span class="k">in</span> <span class="n">prng</span><span class="o">.</span><span class="n">publisher</span> <span class="p">{</span>
        <span class="o">...</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="bottom-line">Bottom line</h2>

<p>Leaving Combine behind is a disruptive step towards both Swift 6 and cross-platform. Personally, I still don’t fully trust the behavior of <code class="language-plaintext highlighter-rouge">AsyncSequence</code>, but what are we left with? Apple is forcing developers towards Concurrency, and soon there will be no choice but to embrace it. And I’m glad, because it’s finally bringing consistency to the language.</p>

<p>We’re close to building the Partout core on both Windows and Linux. In the next article, I will cover some quirks you will face with SwiftPM.</p>]]></content><author><name>Davide De Rosa</name></author><category term="development" /><category term="swift" /><summary type="html"><![CDATA[The very first goal of porting may sound simple: a successful build. Once you manage to just compile your package, the worst is definitely behind you. Keep in mind that this is not a series about how to port Apple frameworks or SwiftUI to other platforms, it’s about the bare Swift language. I want to show you how Xcode may trick you into thinking that some patterns are a key part of Swift, whereas they should be avoided if you plan to leave the Apple ecosystem at some point. Today, I’ll talk about a kind of infamous framework for Swift developers: Combine. Combine is unofficially obsolete When the compiler suddenly stopped at some occurrence of import Combine, I was beaten. Combine has been a fundamental piece of reactive programming for the last 5+ years, and any recent Swift codebase uses Combine to some extent. The scary question was: to what extent was I using it? Let me digress a moment. There is a big problem with Combine, and it’s not about the developers using it. Apple is well-known for disrupting its own frameworks regardless of any backward-compatibility, and Combine is one of those examples where Apple took a different turn without offering a full replacement. Initially, it seemed that SwiftUI was all about Combine, but the introduction of Concurrency made the poor framework an outcast. Unsurprisingly, ObservableObject and @Published are also unavailable outside Apple Swift, but if you’ve been a diligent programmer, you’ve probably learned that those constructs only make sense with SwiftUI. The fact that Combine has never been integrated into the Swift language, reveals that Concurrency is how Swift (and Apple) wants you to perform asynchronous programming from now on. Does Swift natively offer a substitute for the long list of Combine operators? Hell, no, and that’s why people still use Combine. Back to my question. Luckily, my use of Combine in Partout was quite basic, except for one .combineLatest3() that was worth half the effort. Porting to AsyncSequence If you remember, the purpose of Combine is manipulating a sequence of asynchronous values. Swift offers implementations of AsyncSequence like AsyncStream and AsyncThrowingStream to accomplish the same in a linear fashion, typical of the async/await model. What in Combine was: subscription = somePublisherOfStrings() // AnyPublisher&lt;String, Never&gt; .removeDuplicates() .sink { [weak self] in print("String: \($0)") } becomes this with AsyncStream: subscription = Task { [weak self] in var previous: String? for await string in someStreamOfStrings() { // AsyncStream&lt;String&gt; guard string != previous else { continue } print("String: \($0)") previous = string } } Now, a typical way to spawn Combine publishers is with subjects (PassthroughSubject and CurrentValueSubject), that are multicast emitters of values. Multiple programs can subscribe to a subject, listen to its sequence of values, and manipulate them before delivery with the rich offer of Combine operators. We lack such a counterpart in Swift, so I went to roll out my own. My PassthroughStream and CurrentValueStream implement a simple pub/sub pattern with AsyncStream and strict Swift 6.1 Concurrency. They have become the building blocks of all my asynchronous publishers in cross-platform Swift, and by keeping behavior and naming close to Combine (e.g. the .send() method), the refactoring was easier to manage. Steps: Replace Combine subjects with subject streams Return an AsyncStream from a subject with .subscribe() Replace AnyCancellable with Task and for [try] await loops (weak self here) Before: final class RandomGenerator { private let generator = PassthroughSubject&lt;Int, Never&gt;() var publisher: AnyPublisher&lt;Int, Never&gt; { generator.eraseToAnyPublisher() } func run() { generator.send(.random(in: 1...1000)) } } ... let prng = RandomGenerator() var subscription = prng.publisher.sink { [weak self] value in ... } After: final class RandomGenerator { private let generator = PassthroughStream&lt;Int&gt;() var publisher: AsyncStream&lt;Int&gt; { generator.subscribe() } func run() { generator.send(.random(in: 1...1000)) } } ... let prng = RandomGenerator() var subscription = Task { [weak self] in for await value in prng.publisher { ... } } Bottom line Leaving Combine behind is a disruptive step towards both Swift 6 and cross-platform. Personally, I still don’t fully trust the behavior of AsyncSequence, but what are we left with? Apple is forcing developers towards Concurrency, and soon there will be no choice but to embrace it. And I’m glad, because it’s finally bringing consistency to the language. We’re close to building the Partout core on both Windows and Linux. In the next article, I will cover some quirks you will face with SwiftPM.]]></summary></entry><entry><title type="html">Cross-platform Swift: Introduction</title><link href="https://davidederosa.com/cross-platform-swift/" rel="alternate" type="text/html" title="Cross-platform Swift: Introduction" /><published>2025-04-13T00:00:00+02:00</published><updated>2025-04-13T00:00:00+02:00</updated><id>https://davidederosa.com/cross-platform-swift-introduction</id><content type="html" xml:base="https://davidederosa.com/cross-platform-swift/"><![CDATA[<p>As <a href="https://github.com/passepartoutvpn/partout">Partout</a>, my Swift framework for VPN and network configuration on Apple devices, has slowly gained shape, I set foot in an ambitious and novel, pioneering goal: <strong>making Partout a truly multiplatform Swift library</strong>. Also, a library that integrates with multiple programming languages where Swift is the coordinator, with the help of the C interoperability.</p>

<p>It’s challenging, but it’s fun, and it’s the way to port <a href="https://passepartoutvpn.app">Passepartout</a> beyond the Apple platforms. So, here, I will progressively share my discoveries and encourage other people to give Swift a chance as a portable language. The language itself is fantastic. Using it outside Xcode? Not as much, but I’ve observed the trends over the years, and overall, things are getting better.</p>

<p>This <a href="https://developer.apple.com/videos/play/wwdc2024/10197/">video from WWDC 2024</a> where the speaker uses Neovim + CMake made me reflect on the increasing efforts that Apple is making to push Swift into the outer world. Endorsing Neovim to develop Swift is an incredible marketing move to expand on Linux primarily, but I don’t mind it because both Neovim and Swift are amazing products.</p>

<p>Bear with me, this is a <em>very experimental</em> work in progress, that’s why I’d rather start with architectural concepts, and delve into technical details only after confirming that my approaches do well in practice.</p>

<h2 id="leaving-the-apple-toolchain">Leaving the Apple toolchain</h2>

<p>I picked Windows as the starting point of my journey. Windows is as far as one can go with Swift, so if my library works there, porting it to Android and Linux should be easier. In this post I’ll outline some fundamental principles to keep in mind before touching any code.</p>

<p><em>Downloading Swift with WinGet</em>
<img src="/s/posts/2025-04-13-01.png" alt="Downloading Swift with WinGet" /></p>

<h3 id="1-start-with-a-lean-core">1. Start with a lean core</h3>

<p>When I made Partout from the ashes of <a href="https://github.com/passepartoutvpn/tunnelkit">TunnelKit</a>, I put special care into making the library core as lean as possible. No dependencies, no OS implementations, pure Swift. This mantra paid off very well in the long run because you realize how basic the Swift runtime is when you leave the comfortable macOS environment: a stripped version of the Foundation and Dispatch frameworks, not even Combine, and little more. I promise, this will hit you hard the first time.</p>

<p>I was equally shocked, yet positively, when <code class="language-plaintext highlighter-rouge">async</code> methods worked out of the box. This is not about Swift, though, rather about Windows. The level of discomfort I feel when I use Windows puts me in a constant disbelief when things, eventually, work as intended. As in “this is Windows, nothing can work without Visual Studio”. Fun fact: Swift requires the Visual Studio Build Tools.</p>

<p><strong>Challenge #1: Only depend on Foundation.</strong></p>

<h3 id="2-objc-no-thanks">2. ObjC? No, thanks</h3>

<p>Another painful wake-up call: the Swift toolchain does not support ObjC targets in SwiftPM on non-Apple. There are three scenarios:</p>

<ol>
  <li>If you depend on 3rd party Swift packages based on ObjC code, move on to something else. Most of the time there will be better options.</li>
  <li>If you need to write low-level code with Swift, prefer some well-crafted C routines. You’ll thank yourself later.</li>
  <li>If you (like me) have legacy ObjC code –a good amount of my OpenVPN implementation is written in ObjC for performance reasons–, hear me out: it’s going to cause you trouble.</li>
</ol>

<p>As far as I can tell, there are no easy shortcuts to resolve point 3. Keep in mind that the first challenge still applies: pray that your ObjC codebase only depends on Foundation or libraries that <em>you</em> bundle –thus excluding Apple frameworks, or you’re basically screwed.</p>

<p>Assuming that this is the case, you should treat ObjC like any other “foreign” language, which is with an external build tool. Once you build the ObjC code as a static library (e.g. with a <code class="language-plaintext highlighter-rouge">Makefile</code>), you have the option to add it as a binary target to the SwiftPM manifest. The same way you would do with Rust or Go, to name some. Unfortunately, this degrades the otherwise neat automation of SwiftPM.</p>

<p>Currently, I’m exploring a solution to reuse my ObjC code as is with <a href="https://www.mingw-w64.org/">MinGW64</a> and <a href="https://www.gnustep.org/">GNUstep</a>, as you can see in the screenshot below (forgive my swearing after hours of frustrating attempts…). So far, so good, though I’m still concerned with how MSYS2/MinGW64 handles the binary architectures.</p>

<p><strong>Challenge #2: Prefer C over ObjC, if you can.</strong></p>

<p><em>Compiling ObjC with MinGW + GNUstep</em>
<img src="/s/posts/2025-04-13-02.png" alt="Compiling ObjC with MinGW + GNUstep" /></p>

<h3 id="3-implementations">3. Implementations</h3>

<p>I still want to use the keychain and Network Extension on Apple systems. A lean core will inevitably lead to taking Swift targets depending on them out of the core and be imported conditionally. These are the “leaves” of the library, the ones where we have the most freedom, even on the programming language.</p>

<p>When it comes to Partout, this is of the utmost importance because it involves how the VPN functionality is implemented on each operating system. While this is clear to me on Apple (Network Extension), for Windows, I’m looking into the <a href="https://github.com/microsoft/UwpVpnPluginSample">Universal Windows Platform (UWP)</a>. As proof of the freedom we have in this area, the VPN code for Partout on Windows will likely be C#.</p>

<p><strong>Challenge #3: Isolate implementation targets.</strong></p>

<h3 id="4-c-is-the-common-denominator">4. C is the common denominator</h3>

<p>Sad to say, but it doesn’t really matter how cool your Swift library is (replace with any other language). The well-thought classes, the scalable design, the smart patterns, the tricky use of OOP: forget about any of those by the time you expose the library to a different programming language. Nobody cares, really, because interoperability is done in C.</p>

<p>Have you wondered how to expose a Swift protocol with an associatedtype to a Python library, an object with a lifetime, or even just a String? Well, the answer is straightforward: you don’t do that. Instead, you expose C wrappers from Swift with <a href="https://forums.swift.org/t/formalizing-cdecl/40677">@_cdecl</a>, which despite the leading underscore seems to be widely accepted as a pseudostable feature. It goes without saying, you will be limited to the standard C types.</p>

<p>This will be a late stage of the refactoring, today I’m not worried. A solid approach to challenge #1 would definitely make this easier.</p>

<p><strong>Challenge #4: Make your public interface a C API.</strong></p>

<h2 id="bottom-line">Bottom line</h2>

<p>I’m still in the early stages of bringing Swift to Windows, Android, and Linux with Partout, but the path is starting to reveal itself. Keep your core lean and pure Swift, avoid Objective-C where you can, isolate OS-specific implementations, and remember that C is the common ground across platforms. It’s experimental, sometimes frustrating, but genuinely fun—and worth sharing as it unfolds. Expect more on this throughout 2025.</p>]]></content><author><name>Davide De Rosa</name></author><category term="development" /><category term="swift" /><summary type="html"><![CDATA[As Partout, my Swift framework for VPN and network configuration on Apple devices, has slowly gained shape, I set foot in an ambitious and novel, pioneering goal: making Partout a truly multiplatform Swift library. Also, a library that integrates with multiple programming languages where Swift is the coordinator, with the help of the C interoperability. It’s challenging, but it’s fun, and it’s the way to port Passepartout beyond the Apple platforms. So, here, I will progressively share my discoveries and encourage other people to give Swift a chance as a portable language. The language itself is fantastic. Using it outside Xcode? Not as much, but I’ve observed the trends over the years, and overall, things are getting better. This video from WWDC 2024 where the speaker uses Neovim + CMake made me reflect on the increasing efforts that Apple is making to push Swift into the outer world. Endorsing Neovim to develop Swift is an incredible marketing move to expand on Linux primarily, but I don’t mind it because both Neovim and Swift are amazing products. Bear with me, this is a very experimental work in progress, that’s why I’d rather start with architectural concepts, and delve into technical details only after confirming that my approaches do well in practice. Leaving the Apple toolchain I picked Windows as the starting point of my journey. Windows is as far as one can go with Swift, so if my library works there, porting it to Android and Linux should be easier. In this post I’ll outline some fundamental principles to keep in mind before touching any code. Downloading Swift with WinGet 1. Start with a lean core When I made Partout from the ashes of TunnelKit, I put special care into making the library core as lean as possible. No dependencies, no OS implementations, pure Swift. This mantra paid off very well in the long run because you realize how basic the Swift runtime is when you leave the comfortable macOS environment: a stripped version of the Foundation and Dispatch frameworks, not even Combine, and little more. I promise, this will hit you hard the first time. I was equally shocked, yet positively, when async methods worked out of the box. This is not about Swift, though, rather about Windows. The level of discomfort I feel when I use Windows puts me in a constant disbelief when things, eventually, work as intended. As in “this is Windows, nothing can work without Visual Studio”. Fun fact: Swift requires the Visual Studio Build Tools. Challenge #1: Only depend on Foundation. 2. ObjC? No, thanks Another painful wake-up call: the Swift toolchain does not support ObjC targets in SwiftPM on non-Apple. There are three scenarios: If you depend on 3rd party Swift packages based on ObjC code, move on to something else. Most of the time there will be better options. If you need to write low-level code with Swift, prefer some well-crafted C routines. You’ll thank yourself later. If you (like me) have legacy ObjC code –a good amount of my OpenVPN implementation is written in ObjC for performance reasons–, hear me out: it’s going to cause you trouble. As far as I can tell, there are no easy shortcuts to resolve point 3. Keep in mind that the first challenge still applies: pray that your ObjC codebase only depends on Foundation or libraries that you bundle –thus excluding Apple frameworks, or you’re basically screwed. Assuming that this is the case, you should treat ObjC like any other “foreign” language, which is with an external build tool. Once you build the ObjC code as a static library (e.g. with a Makefile), you have the option to add it as a binary target to the SwiftPM manifest. The same way you would do with Rust or Go, to name some. Unfortunately, this degrades the otherwise neat automation of SwiftPM. Currently, I’m exploring a solution to reuse my ObjC code as is with MinGW64 and GNUstep, as you can see in the screenshot below (forgive my swearing after hours of frustrating attempts…). So far, so good, though I’m still concerned with how MSYS2/MinGW64 handles the binary architectures. Challenge #2: Prefer C over ObjC, if you can. Compiling ObjC with MinGW + GNUstep 3. Implementations I still want to use the keychain and Network Extension on Apple systems. A lean core will inevitably lead to taking Swift targets depending on them out of the core and be imported conditionally. These are the “leaves” of the library, the ones where we have the most freedom, even on the programming language. When it comes to Partout, this is of the utmost importance because it involves how the VPN functionality is implemented on each operating system. While this is clear to me on Apple (Network Extension), for Windows, I’m looking into the Universal Windows Platform (UWP). As proof of the freedom we have in this area, the VPN code for Partout on Windows will likely be C#. Challenge #3: Isolate implementation targets. 4. C is the common denominator Sad to say, but it doesn’t really matter how cool your Swift library is (replace with any other language). The well-thought classes, the scalable design, the smart patterns, the tricky use of OOP: forget about any of those by the time you expose the library to a different programming language. Nobody cares, really, because interoperability is done in C. Have you wondered how to expose a Swift protocol with an associatedtype to a Python library, an object with a lifetime, or even just a String? Well, the answer is straightforward: you don’t do that. Instead, you expose C wrappers from Swift with @_cdecl, which despite the leading underscore seems to be widely accepted as a pseudostable feature. It goes without saying, you will be limited to the standard C types. This will be a late stage of the refactoring, today I’m not worried. A solid approach to challenge #1 would definitely make this easier. Challenge #4: Make your public interface a C API. Bottom line I’m still in the early stages of bringing Swift to Windows, Android, and Linux with Partout, but the path is starting to reveal itself. Keep your core lean and pure Swift, avoid Objective-C where you can, isolate OS-specific implementations, and remember that C is the common ground across platforms. It’s experimental, sometimes frustrating, but genuinely fun—and worth sharing as it unfolds. Expect more on this throughout 2025.]]></summary></entry><entry><title type="html">Who cares about performance?</title><link href="https://davidederosa.com/2025/03/who-cares-about-performance/" rel="alternate" type="text/html" title="Who cares about performance?" /><published>2025-03-25T00:00:00+01:00</published><updated>2025-03-25T00:00:00+01:00</updated><id>https://davidederosa.com/2025/03/who-cares-about-performance</id><content type="html" xml:base="https://davidederosa.com/2025/03/who-cares-about-performance/"><![CDATA[<p>While many people copy and paste unoriginal thoughts about AI and the so-called “vibe coding”, it seems that what used to make software valuable is constantly put aside. If you try to argue that tech <em>does</em> matter in a tech-oriented product, they will tell you that:</p>

<ul>
  <li>Business is more important than engineering</li>
  <li>Software is useless if it doesn’t make money</li>
  <li>Users only care about features</li>
  <li>Devices are powerful, performance doesn’t matter</li>
  <li>Internet is fast, a few more GBs won’t hurt</li>
</ul>

<p>And many more dumb takes. This is the typical mentality by which consultancy firms produce the most mediocre products you will ever find.</p>

<p>I don’t want to delve into this endless – and hopeless – topic. Instead, I want to tell you a little story of how easy it is to lose control of software <em>performance</em>, and how the understanding of programming fundamentals keeps us in touch with reality. This has never been more important with the fast-paced opportunities that LLMs offer today.</p>

<h3 id="can-you-afford-low-performance">Can you afford low performance?</h3>

<p>I’m far from being a low-level programmer, yet I know C and the fundamentals of how things happen below the code.</p>

<p><a href="https://passepartoutvpn.app">Passepartout</a> is a networking app mostly dealing with VPN connections. At least in the tunnel context, performance <em>does</em> matter. When it comes to OpenVPN in particular, it’s very hard to compete with a pure C codebase – the official library – when you also have to account for the overhead of the Swift runtime. Let’s not forget about the <a href="https://developer.apple.com/forums/thread/73148">strict memory limits</a> of Network Extension either. The time I spent on profiling to improve efficiency, resolve memory leaks, and reduce the crash rate, among other things, is pretty massive.</p>

<p>Two months ago, a user reported a regression in the OpenVPN negotiation where the handshake would never complete. I could implement a fix quickly, yet the handshake took 4x longer than with the obsolete TunnelKit. A whopping and unacceptable 20-25s vs 5s negotiation!</p>

<h3 id="the-domino-effect-of-bad-choices">The domino effect of bad choices</h3>

<p>I inspected the negotiation steps carefully for bottlenecks:</p>

<ul>
  <li>Loops</li>
  <li>Blocking code</li>
  <li>Slow I/O</li>
  <li>Disputed locks</li>
  <li>Wrong artificial delays</li>
  <li>Parsing</li>
  <li>…and whatnot!</li>
</ul>

<p>Now, if your life as a programmer only revolved around high-level languages like JavaScript, Python, or even Swift, you will have a hard time realizing the <em>time cost</em> – not the <em>O(n)</em> cost – of your code. Similar to how knowing <a href="https://en.wikipedia.org/wiki/SQL">SQL</a> helps immensely when profiling a slow <a href="https://en.wikipedia.org/wiki/Object%E2%80%93relational_mapping">ORM</a>, knowing C helps you spot poor performance in high-level programs, even if you never get to write C code.</p>

<p>It took me 1-2 days to realize that the culprit was ironically where I expected it the least. The performance hit was caused by <a href="https://github.com/passepartoutvpn/passepartout/pull/1095">the parser of the PUSH_REPLY</a> message, which is a short comma-separated string. To be fair, the parser is quite basic, so it wasn’t the parser either: the problem was about <strong>re-creating the <code class="language-plaintext highlighter-rouge">NSRegularExpression</code> objects every time a new PUSH_REPLY was parsed</strong>.</p>

<p>Of course, it doesn’t take a lot to create an <code class="language-plaintext highlighter-rouge">NSRegularExpression</code> but the user’s server sent dozens of PUSH_REPLY messages to the client, so the slow code was adding up very quickly. Run a 100ms vs 500ms code once and it will be okay, but run it 20 times and you easily get a 2 seconds vs 10 seconds delay. In the vast majority of servers, the PUSH_REPLY is a single message, which made the nasty issue unnoticeable to most.</p>

<p>By then, I realized how too much OOP makes us programmers forget that even creating objects may be expensive. Imagine what AI can do without a supervisor. When performance is crucial, we should remind ourselves that the convenient, good-looking solution might be the <em>worse</em> choice.</p>

<h3 id="what-vibe-coders-may-not-be-ready-for">What “vibe coders” may not be ready for</h3>

<p>Before anything, ask yourself what <em>your business</em> is about. If you work at Netflix, or in the game industry, you might observe the immediate effect of an inefficient vibe-coded algorithm. In the trivial CRUD apps that make up 99.9% of the consultancy workforce, instead, you may only realize that your code has low performance after a long chain of bad choices, if ever.</p>

<p>Performance, however, is just an example of what’s being overseen due to the increasingly fast pace at which people produce code.</p>

<p>This leads to a few observations:</p>

<ul>
  <li>If your software is “stupid”, low performance may only be hidden and therefore not seem a big deal.</li>
  <li>Engineers who underestimate the importance of performant solutions, probably never worked on challenging projects.</li>
  <li>If performance doesn’t matter to <em>you</em> today, it doesn’t mean it’s not important in general. Or, that it won’t be important when <em>your</em> business scales up.</li>
</ul>

<p>When that day comes, will you have the knowledge you need to face it?</p>]]></content><author><name>Davide De Rosa</name></author><category term="development" /><category term="swift" /><summary type="html"><![CDATA[While many people copy and paste unoriginal thoughts about AI and the so-called “vibe coding”, it seems that what used to make software valuable is constantly put aside. If you try to argue that tech does matter in a tech-oriented product, they will tell you that: Business is more important than engineering Software is useless if it doesn’t make money Users only care about features Devices are powerful, performance doesn’t matter Internet is fast, a few more GBs won’t hurt And many more dumb takes. This is the typical mentality by which consultancy firms produce the most mediocre products you will ever find. I don’t want to delve into this endless – and hopeless – topic. Instead, I want to tell you a little story of how easy it is to lose control of software performance, and how the understanding of programming fundamentals keeps us in touch with reality. This has never been more important with the fast-paced opportunities that LLMs offer today. Can you afford low performance? I’m far from being a low-level programmer, yet I know C and the fundamentals of how things happen below the code. Passepartout is a networking app mostly dealing with VPN connections. At least in the tunnel context, performance does matter. When it comes to OpenVPN in particular, it’s very hard to compete with a pure C codebase – the official library – when you also have to account for the overhead of the Swift runtime. Let’s not forget about the strict memory limits of Network Extension either. The time I spent on profiling to improve efficiency, resolve memory leaks, and reduce the crash rate, among other things, is pretty massive. Two months ago, a user reported a regression in the OpenVPN negotiation where the handshake would never complete. I could implement a fix quickly, yet the handshake took 4x longer than with the obsolete TunnelKit. A whopping and unacceptable 20-25s vs 5s negotiation! The domino effect of bad choices I inspected the negotiation steps carefully for bottlenecks: Loops Blocking code Slow I/O Disputed locks Wrong artificial delays Parsing …and whatnot! Now, if your life as a programmer only revolved around high-level languages like JavaScript, Python, or even Swift, you will have a hard time realizing the time cost – not the O(n) cost – of your code. Similar to how knowing SQL helps immensely when profiling a slow ORM, knowing C helps you spot poor performance in high-level programs, even if you never get to write C code. It took me 1-2 days to realize that the culprit was ironically where I expected it the least. The performance hit was caused by the parser of the PUSH_REPLY message, which is a short comma-separated string. To be fair, the parser is quite basic, so it wasn’t the parser either: the problem was about re-creating the NSRegularExpression objects every time a new PUSH_REPLY was parsed. Of course, it doesn’t take a lot to create an NSRegularExpression but the user’s server sent dozens of PUSH_REPLY messages to the client, so the slow code was adding up very quickly. Run a 100ms vs 500ms code once and it will be okay, but run it 20 times and you easily get a 2 seconds vs 10 seconds delay. In the vast majority of servers, the PUSH_REPLY is a single message, which made the nasty issue unnoticeable to most. By then, I realized how too much OOP makes us programmers forget that even creating objects may be expensive. Imagine what AI can do without a supervisor. When performance is crucial, we should remind ourselves that the convenient, good-looking solution might be the worse choice. What “vibe coders” may not be ready for Before anything, ask yourself what your business is about. If you work at Netflix, or in the game industry, you might observe the immediate effect of an inefficient vibe-coded algorithm. In the trivial CRUD apps that make up 99.9% of the consultancy workforce, instead, you may only realize that your code has low performance after a long chain of bad choices, if ever. Performance, however, is just an example of what’s being overseen due to the increasingly fast pace at which people produce code. This leads to a few observations: If your software is “stupid”, low performance may only be hidden and therefore not seem a big deal. Engineers who underestimate the importance of performant solutions, probably never worked on challenging projects. If performance doesn’t matter to you today, it doesn’t mean it’s not important in general. Or, that it won’t be important when your business scales up. When that day comes, will you have the knowledge you need to face it?]]></summary></entry><entry><title type="html">Frontend development is easy</title><link href="https://davidederosa.com/2025/03/frontend-development-is-easy/" rel="alternate" type="text/html" title="Frontend development is easy" /><published>2025-03-19T00:00:00+01:00</published><updated>2025-03-19T00:00:00+01:00</updated><id>https://davidederosa.com/2025/03/frontend-development-is-easy</id><content type="html" xml:base="https://davidederosa.com/2025/03/frontend-development-is-easy/"><![CDATA[<p>If you are a developer, you have heard this statement at least once. While I believe that any comparison is pointless because <em>everything</em> is about programming, I’d like to add some complexities often neglected in frontend development, within the context of client/server software.</p>

<h2 id="take-it-seriously">Take it seriously</h2>

<p>Frontend is not a toy. What I find frequent in frontend developers is the <em>recklessness</em> of their choices. Backend developers tend to be more conservative because they are the ones receiving that phone call at night when a service is down, but this doesn’t mean that a frontend bug couldn’t have terrible consequences.</p>

<p>Some people claim that backend is harder than frontend because of the “more serious” problems it has to solve:</p>

<ul>
  <li>Performance</li>
  <li>Scalability</li>
  <li>Robustness</li>
  <li>Concurrency</li>
</ul>

<p>For some reason, those qualities are considered less of a priority for a well-written client, but they are equally important and sometimes <em>more</em> important. Users may spot slow, sluggish, power-hungry, buggy apps from a distance.</p>

<p>It’s also true that if you skip native backend software like web servers or databases, which are a <em>big deal</em>, most developers out there are doing simple web services. Let’s be honest: nowadays, most of the above difficulties are not dealt with at the programming level, they are delegated to long-established SaaS platforms. This is great, but only because backend developers are –in my experience– generally more aware of how things happen under the hood.</p>

<p>Sadly, frontend frameworks lead developers in the opposite direction: they make you forget the consequences of bad programming practices. They deviate from the importance of appropriate data structures and algorithms. They convince you that modern machines can endure any load. They overcomplicate code with tons of boilerplate. They waste your time moving your focus on things that nobody cares about e.g. “is that a view or a view model?”. They make you lose the foundations of programming.</p>

<p>The result is a far west full of cowboys writing inefficient, dangerous code, but this is not a problem of the frontend itself.</p>

<h2 id="never-rely-on-a-backend">Never rely on a backend</h2>

<p>Not all apps are web-oriented, and <a href="https://passepartoutvpn.app">Passepartout</a> is an example of frontend development without a backend. Or, better said, frontend development with an uncontrolled backend.</p>

<p>What does this imply? You take <em>direct responsibility</em> for your software. In a world where most apps interact with external APIs, it’s appalling how often frontend developers operate in the best-case scenario where everything works as expected.</p>

<p>I wonder how many write code that, to name a few:</p>

<ul>
  <li>Expects malformed responses</li>
  <li>Expects no responses</li>
  <li>Handles timeouts</li>
  <li>Works fully offline</li>
  <li>Works headless (without views)</li>
  <li>Migrates persistent data without data loss</li>
</ul>

<p>This is your responsibility, not the external backend’s, and you do that by giving your frontend <em>a local backend</em> with business logic to rely on. At that point, the presence of an external backend will be of marginal importance.</p>

<h2 id="domain-before-ui">Domain before UI</h2>

<p>Business logic is another concept that, historically, the backend is more used to than the frontend. I believe that backend developers don’t see the immediate effect of their work until late, whereas
it takes a few minutes to create a meaningful UI. The instant gratification that comes from “it works!” may indefinitely delay the key decisions to take early in software development.</p>

<p>Presentation is the highest layer in software design, yet in frontend development, the importance of UI is constantly glorified. No surprise, non-tech people and the industry in general judge software from the UI, but frontend developers should prioritize the <em>domain</em> like any other non-UI developer does.</p>

<p>Any software should make sense regardless of having a UI, or a remote API, and frontend makes no exception: UI is no more than the visual representation of a domain. I believe that this simple rule also <em>dignifies</em> frontend apps for making them way more meaningful than “a couple of screens”.</p>

<h2 id="troubleshooting">Troubleshooting</h2>

<p>How much time do you waste interpreting users’ feedback for the lack of better options? What if you are in a real hurry to solve a frontend problem in production? Clients live in the most unpredictable environments, yet the troubleshooting of their errors is often deferred to backend monitoring.</p>

<p>Logging, proper error handling, profiling, and tracking tools are a superpower, but as long as the backend takes care of that, the frontend couldn’t care less. Drop the backend, and troubleshooting becomes a nightmare. Along the lines of “never rely on a backend”, do your homework and invest decent time in logging at least. Make it a requirement, even more than tests. It’s tedious, it’s time-consuming, but it truly pays off when SHTF.</p>

<p>Logging is a fundamental trait of software robustness, and it takes a lot of practice to describe what code does through human-readable text in a way that will help your future self later. No software is exempt from the need for logging.</p>

<h2 id="in-conclusion">In conclusion</h2>

<p>Frontend is the face of our product, but UI is only a small part of it. Over the years, the overuse of client-side JavaScript frameworks has made frontend software less of an example of good software design. At the end of the day, though, all design principles still apply, and frontend development deserves the same care and rigor as any other layer of software development.</p>]]></content><author><name>Davide De Rosa</name></author><category term="development" /><summary type="html"><![CDATA[If you are a developer, you have heard this statement at least once. While I believe that any comparison is pointless because everything is about programming, I’d like to add some complexities often neglected in frontend development, within the context of client/server software. Take it seriously Frontend is not a toy. What I find frequent in frontend developers is the recklessness of their choices. Backend developers tend to be more conservative because they are the ones receiving that phone call at night when a service is down, but this doesn’t mean that a frontend bug couldn’t have terrible consequences. Some people claim that backend is harder than frontend because of the “more serious” problems it has to solve: Performance Scalability Robustness Concurrency For some reason, those qualities are considered less of a priority for a well-written client, but they are equally important and sometimes more important. Users may spot slow, sluggish, power-hungry, buggy apps from a distance. It’s also true that if you skip native backend software like web servers or databases, which are a big deal, most developers out there are doing simple web services. Let’s be honest: nowadays, most of the above difficulties are not dealt with at the programming level, they are delegated to long-established SaaS platforms. This is great, but only because backend developers are –in my experience– generally more aware of how things happen under the hood. Sadly, frontend frameworks lead developers in the opposite direction: they make you forget the consequences of bad programming practices. They deviate from the importance of appropriate data structures and algorithms. They convince you that modern machines can endure any load. They overcomplicate code with tons of boilerplate. They waste your time moving your focus on things that nobody cares about e.g. “is that a view or a view model?”. They make you lose the foundations of programming. The result is a far west full of cowboys writing inefficient, dangerous code, but this is not a problem of the frontend itself. Never rely on a backend Not all apps are web-oriented, and Passepartout is an example of frontend development without a backend. Or, better said, frontend development with an uncontrolled backend. What does this imply? You take direct responsibility for your software. In a world where most apps interact with external APIs, it’s appalling how often frontend developers operate in the best-case scenario where everything works as expected. I wonder how many write code that, to name a few: Expects malformed responses Expects no responses Handles timeouts Works fully offline Works headless (without views) Migrates persistent data without data loss This is your responsibility, not the external backend’s, and you do that by giving your frontend a local backend with business logic to rely on. At that point, the presence of an external backend will be of marginal importance. Domain before UI Business logic is another concept that, historically, the backend is more used to than the frontend. I believe that backend developers don’t see the immediate effect of their work until late, whereas it takes a few minutes to create a meaningful UI. The instant gratification that comes from “it works!” may indefinitely delay the key decisions to take early in software development. Presentation is the highest layer in software design, yet in frontend development, the importance of UI is constantly glorified. No surprise, non-tech people and the industry in general judge software from the UI, but frontend developers should prioritize the domain like any other non-UI developer does. Any software should make sense regardless of having a UI, or a remote API, and frontend makes no exception: UI is no more than the visual representation of a domain. I believe that this simple rule also dignifies frontend apps for making them way more meaningful than “a couple of screens”. Troubleshooting How much time do you waste interpreting users’ feedback for the lack of better options? What if you are in a real hurry to solve a frontend problem in production? Clients live in the most unpredictable environments, yet the troubleshooting of their errors is often deferred to backend monitoring. Logging, proper error handling, profiling, and tracking tools are a superpower, but as long as the backend takes care of that, the frontend couldn’t care less. Drop the backend, and troubleshooting becomes a nightmare. Along the lines of “never rely on a backend”, do your homework and invest decent time in logging at least. Make it a requirement, even more than tests. It’s tedious, it’s time-consuming, but it truly pays off when SHTF. Logging is a fundamental trait of software robustness, and it takes a lot of practice to describe what code does through human-readable text in a way that will help your future self later. No software is exempt from the need for logging. In conclusion Frontend is the face of our product, but UI is only a small part of it. Over the years, the overuse of client-side JavaScript frameworks has made frontend software less of an example of good software design. At the end of the day, though, all design principles still apply, and frontend development deserves the same care and rigor as any other layer of software development.]]></summary></entry><entry><title type="html">Rewriting Passepartout for v3</title><link href="https://davidederosa.com/2025/03/rewriting-passepartout-for-v3/" rel="alternate" type="text/html" title="Rewriting Passepartout for v3" /><published>2025-03-11T00:00:00+01:00</published><updated>2025-03-11T00:00:00+01:00</updated><id>https://davidederosa.com/2025/03/rewriting-passepartout-for-v3</id><content type="html" xml:base="https://davidederosa.com/2025/03/rewriting-passepartout-for-v3/"><![CDATA[<p>For software to live a long life, it must grow together with our experience. If our skills improve at a faster pace than we maintain our software, its design will start to drift away from our standards and expectations. If we let the gap increase for too long, it will eventually be impossible to catch up, and we’ll end up hating our creations.</p>

<h2 id="version-2-was-a-mess">Version 2 was a mess</h2>

<p><a href="https://passepartoutvpn.app">Passepartout</a> used to be two separate iOS and macOS apps, with all the complications that this implies. In 2022, I used Passepartout to learn <a href="https://developer.apple.com/xcode/swiftui/">SwiftUI</a> –I considered Flutter initially– and make v2 a partially multiplatform app. Partially because the macOS app was a hybrid <a href="https://developer.apple.com/mac-catalyst/">Catalyst/iPad</a> app, a terrible choice if I think of it today. I don’t even know why I did it, but whatever.</p>

<p>The conclusions I drew after v2:</p>

<ul>
  <li>SwiftUI is very hard to get right. I had to rewrite my views multiple times due to my wrong understanding of the framework.</li>
  <li>Catalyst made the macOS app an ugly and unstable iPadOS app, let alone a complete nightmare to develop.</li>
  <li>The time I spent on the Mac system menu, in particular, was beyond ridiculous. Maybe I’ll dedicate a post to this clunky Catalyst/AppKit interaction.</li>
  <li>The app core was overengineered, untested, untestable, and confusing.</li>
  <li><a href="https://github.com/passepartoutvpn/tunnelkit">TunnelKit</a> was already unmanageable and inextensible. Touching the wrong line could break connectivity for thousands of users.</li>
</ul>

<p>I’m aware that we, developers, occasionally suffer an innate tendency to be unsatisfied with our choices, whatever they are. Redoing the same things over and over is detrimental to making progress, though. Therefore, rewriting software should <em>never</em> be your first choice. That’s why I ruminated around the idea for months, but the rewrite was inevitable 7 years after the first release.</p>

<p>Users don’t and can’t realize the amount of bugs that Passepartout v2 and TunnelKit had. The codebase, <em>my codebase</em>, was such a high barrier that it took me a year (2022 to 2023) to resolve some legitimate concerns with iCloud. Requests/bugs were sadly flowing at 30x the speed I was able to address them. The app was half abandoned.</p>

<p>It’s, however, very risky to rewrite an app that was stable, making decent money, and required very little support despite a user base in the hundreds of thousands. To end up, one year later, with the same app with more or less the same features.</p>

<p>Rewriting must be <em>really</em> worth it.</p>

<h2 id="the-costbenefit-of-rewriting-software">The cost/benefit of rewriting software</h2>

<p>Version 3 is the last time I <em>intend</em> to attack the foundations of Passepartout.</p>

<p>So many times I rewrote code in my life with the sole intent of working in a “beautiful” codebase, not realizing how quickly the enthusiasm wanes when the development routine is back to normal. Give it a few months and, no matter what, your codebase will look “ugly” again. It never ends.</p>

<p>I learned not to rely on “beauty” to bring me back to the joy of programming. After all, when I wrote those nasty lines 10 years ago, I probably thought it was the state of the art. Right?</p>

<p>Today, I try to refactor software as a regular exercise, but at a smaller scale, and with a different purpose:</p>

<p><strong>Make my changes last as long as possible.</strong></p>

<p>Below is what I did in 2024 –part-time until August– for this major update:</p>

<ul>
  <li><a href="https://github.com/orgs/passepartoutvpn/projects/1/views/4?filterQuery=">The GitHub Project for v3</a></li>
  <li><a href="https://github.com/orgs/passepartoutvpn/projects/1/views/8?filterQuery=">The tasks split by goal</a></li>
</ul>

<p>The project encompassed ~1000 items, of which ~350 are invisible for being in private repositories. An insane amount of work, in hindsight.</p>

<p>Today, I can confirm that it was by no means a waste of time. After one year of development, the success of this reengineering is summarized in a sentence:</p>

<p><strong>Most areas of Passepartout won’t need to be modified for years to come.</strong></p>

<p>This is the single measure you want to focus on when considering a big architectural redesign: the time you save in the long run must dramatically compensate for the effort of rewriting. With this mantra, good design will be the natural consequence. Because good design, ultimately, is meant to save development time.</p>

<p>The best code of your software is the one you forget about, the one you don’t need to touch ever again.</p>]]></content><author><name>Davide De Rosa</name></author><category term="development" /><category term="refactoring" /><category term="planning" /><summary type="html"><![CDATA[For software to live a long life, it must grow together with our experience. If our skills improve at a faster pace than we maintain our software, its design will start to drift away from our standards and expectations. If we let the gap increase for too long, it will eventually be impossible to catch up, and we’ll end up hating our creations. Version 2 was a mess Passepartout used to be two separate iOS and macOS apps, with all the complications that this implies. In 2022, I used Passepartout to learn SwiftUI –I considered Flutter initially– and make v2 a partially multiplatform app. Partially because the macOS app was a hybrid Catalyst/iPad app, a terrible choice if I think of it today. I don’t even know why I did it, but whatever. The conclusions I drew after v2: SwiftUI is very hard to get right. I had to rewrite my views multiple times due to my wrong understanding of the framework. Catalyst made the macOS app an ugly and unstable iPadOS app, let alone a complete nightmare to develop. The time I spent on the Mac system menu, in particular, was beyond ridiculous. Maybe I’ll dedicate a post to this clunky Catalyst/AppKit interaction. The app core was overengineered, untested, untestable, and confusing. TunnelKit was already unmanageable and inextensible. Touching the wrong line could break connectivity for thousands of users. I’m aware that we, developers, occasionally suffer an innate tendency to be unsatisfied with our choices, whatever they are. Redoing the same things over and over is detrimental to making progress, though. Therefore, rewriting software should never be your first choice. That’s why I ruminated around the idea for months, but the rewrite was inevitable 7 years after the first release. Users don’t and can’t realize the amount of bugs that Passepartout v2 and TunnelKit had. The codebase, my codebase, was such a high barrier that it took me a year (2022 to 2023) to resolve some legitimate concerns with iCloud. Requests/bugs were sadly flowing at 30x the speed I was able to address them. The app was half abandoned. It’s, however, very risky to rewrite an app that was stable, making decent money, and required very little support despite a user base in the hundreds of thousands. To end up, one year later, with the same app with more or less the same features. Rewriting must be really worth it. The cost/benefit of rewriting software Version 3 is the last time I intend to attack the foundations of Passepartout. So many times I rewrote code in my life with the sole intent of working in a “beautiful” codebase, not realizing how quickly the enthusiasm wanes when the development routine is back to normal. Give it a few months and, no matter what, your codebase will look “ugly” again. It never ends. I learned not to rely on “beauty” to bring me back to the joy of programming. After all, when I wrote those nasty lines 10 years ago, I probably thought it was the state of the art. Right? Today, I try to refactor software as a regular exercise, but at a smaller scale, and with a different purpose: Make my changes last as long as possible. Below is what I did in 2024 –part-time until August– for this major update: The GitHub Project for v3 The tasks split by goal The project encompassed ~1000 items, of which ~350 are invisible for being in private repositories. An insane amount of work, in hindsight. Today, I can confirm that it was by no means a waste of time. After one year of development, the success of this reengineering is summarized in a sentence: Most areas of Passepartout won’t need to be modified for years to come. This is the single measure you want to focus on when considering a big architectural redesign: the time you save in the long run must dramatically compensate for the effort of rewriting. With this mantra, good design will be the natural consequence. Because good design, ultimately, is meant to save development time. The best code of your software is the one you forget about, the one you don’t need to touch ever again.]]></summary></entry><entry><title type="html">Deploying to the App Store: The cost you didn’t expect</title><link href="https://davidederosa.com/2025/03/deploying-to-the-app-store-the-cost-you-didn-t-expect/" rel="alternate" type="text/html" title="Deploying to the App Store: The cost you didn’t expect" /><published>2025-03-03T00:00:00+01:00</published><updated>2025-03-03T00:00:00+01:00</updated><id>https://davidederosa.com/2025/03/deploying-to-the-app-store-the-cost-you-didn-t-expect</id><content type="html" xml:base="https://davidederosa.com/2025/03/deploying-to-the-app-store-the-cost-you-didn-t-expect/"><![CDATA[<p>Passepartout has had a <a href="https://github.com/passepartoutvpn/passepartout/actions/runs/13551048532">solid and unique CI/CD workflow</a> for years, from Git commits straight to the App Store. For iPhone, iPad, Mac, and Apple TV.</p>

<p>I dare to say, automated releases are hardly (if <em>ever</em>) seen in open-source *OS apps.</p>

<p><a href="https://docs.fastlane.tools/">fastlane</a>, created by <a href="https://krausefx.com/">Felix Krause</a>, and <a href="https://github.com/features/actions">GitHub Actions</a> helped me immensely with the fast turnaround of Passepartout releases. In the era of LLMs, you have no excuses to waste time for not using these incredible tools.</p>

<p>Let me show why CI/CD is one of the most important and underestimated aspects of making indie software, or software in general.</p>

<h3 id="its-just-an-app-right">It’s just an app, right?</h3>

<p>Many people are confident that <em>The Idea</em> is the most valuable aspect of a product.</p>

<p>Unfortunately, if you developed an app for the App Store, at any level of complexity, you know how exhausting the whole process is. There is so much more than “writing the code”, which is nothing trivial to start with.</p>

<h3 id="the-app-store-requirements-will-beat-you">The App Store requirements will beat you</h3>

<p>Choosing the icons. Crafting the screenshots. Writing the metadata. Picking the categories. Localizations. The business model. In-app purchases. Sorting out the legal aspects. The App Review process. And so on.</p>

<p>Wait, have I mentioned the codesigning process? Development, Ad-Hoc, Distribution. Multiple platforms. Debug and Release.</p>

<p>Especially at the beginning, it’s overwhelming and discouraging. We’ve all been there.</p>

<p>The 15-30% cut that Apple takes from your revenue is almost a marginal cost compared to all this.</p>

<h3 id="the-fear-of-change">The fear of change</h3>

<p>Here’s a very subtle side-effect of the above: once your tedious setup finally works, you might <em>refrain from changing</em>.</p>

<p>Some relatable examples:</p>

<ul>
  <li>If I change the UI, I will have to change the screenshots for X languages and Y platforms.</li>
  <li>If I alter some inner logic, I will get a rejection from Apple.</li>
  <li>If I introduce a regression, I will get bad reviews.</li>
  <li>Even if I have a hotfix in time, Apple will push my release back for silly reasons.</li>
</ul>

<p>It goes without saying, this is an atrocious outcome for your product. If you work alone with no one to delegate these annoyances to, you risk falling into the ultimate recipe for failure.</p>

<p><em>Stagnation is the hidden cost of expensive deployment.</em></p>

<h3 id="you-must-learn-to-automate">You MUST learn to automate</h3>

<p>The key to keeping focus on the product is <em>automation</em>. It’s boring at first, but in the long run, it’s your best bet against the inevitable frustration of using App Store Connect.</p>

<ul>
  <li>If you find yourself doing 3+ times the same task, automate it.</li>
  <li>If a task doesn’t need constant interaction, automate it.</li>
  <li>If a task is sensitive to human mistakes, automate it.</li>
</ul>

<p>Observe your routine and you will soon realize how many hours you are wasting on dumb tasks, time you could have spent on useful features for your customers.</p>

<h3 id="continuous-integration-is-underused">Continuous integration is underused!</h3>

<p>After 15 years working with Apple devices, I can still confirm this trend: the vast majority of iOS developers don’t know jack about <em>continuous integration</em>. Which is crazy because fastlane has been around since 2014. GitHub Actions has a shorter history, but there have always been alternatives: Travis-CI, GitLab, Circle-CI, and whatnot.</p>

<p>In the next posts, I’ll show you how I used fastlane and GitHub Actions to automate the release of Passepartout for iOS, macOS, and tvOS at once.</p>

<p>Stay in touch.</p>]]></content><author><name>Davide De Rosa</name></author><category term="development" /><category term="ci/cd" /><summary type="html"><![CDATA[Passepartout has had a solid and unique CI/CD workflow for years, from Git commits straight to the App Store. For iPhone, iPad, Mac, and Apple TV. I dare to say, automated releases are hardly (if ever) seen in open-source *OS apps. fastlane, created by Felix Krause, and GitHub Actions helped me immensely with the fast turnaround of Passepartout releases. In the era of LLMs, you have no excuses to waste time for not using these incredible tools. Let me show why CI/CD is one of the most important and underestimated aspects of making indie software, or software in general. It’s just an app, right? Many people are confident that The Idea is the most valuable aspect of a product. Unfortunately, if you developed an app for the App Store, at any level of complexity, you know how exhausting the whole process is. There is so much more than “writing the code”, which is nothing trivial to start with. The App Store requirements will beat you Choosing the icons. Crafting the screenshots. Writing the metadata. Picking the categories. Localizations. The business model. In-app purchases. Sorting out the legal aspects. The App Review process. And so on. Wait, have I mentioned the codesigning process? Development, Ad-Hoc, Distribution. Multiple platforms. Debug and Release. Especially at the beginning, it’s overwhelming and discouraging. We’ve all been there. The 15-30% cut that Apple takes from your revenue is almost a marginal cost compared to all this. The fear of change Here’s a very subtle side-effect of the above: once your tedious setup finally works, you might refrain from changing. Some relatable examples: If I change the UI, I will have to change the screenshots for X languages and Y platforms. If I alter some inner logic, I will get a rejection from Apple. If I introduce a regression, I will get bad reviews. Even if I have a hotfix in time, Apple will push my release back for silly reasons. It goes without saying, this is an atrocious outcome for your product. If you work alone with no one to delegate these annoyances to, you risk falling into the ultimate recipe for failure. Stagnation is the hidden cost of expensive deployment. You MUST learn to automate The key to keeping focus on the product is automation. It’s boring at first, but in the long run, it’s your best bet against the inevitable frustration of using App Store Connect. If you find yourself doing 3+ times the same task, automate it. If a task doesn’t need constant interaction, automate it. If a task is sensitive to human mistakes, automate it. Observe your routine and you will soon realize how many hours you are wasting on dumb tasks, time you could have spent on useful features for your customers. Continuous integration is underused! After 15 years working with Apple devices, I can still confirm this trend: the vast majority of iOS developers don’t know jack about continuous integration. Which is crazy because fastlane has been around since 2014. GitHub Actions has a shorter history, but there have always been alternatives: Travis-CI, GitLab, Circle-CI, and whatnot. In the next posts, I’ll show you how I used fastlane and GitHub Actions to automate the release of Passepartout for iOS, macOS, and tvOS at once. Stay in touch.]]></summary></entry><entry><title type="html">The path to an obscure crash</title><link href="https://davidederosa.com/2025/03/the-path-to-an-obscure-crash/" rel="alternate" type="text/html" title="The path to an obscure crash" /><published>2025-03-02T00:00:00+01:00</published><updated>2025-03-02T00:00:00+01:00</updated><id>https://davidederosa.com/2025/03/the-path-to-an-obscure-crash</id><content type="html" xml:base="https://davidederosa.com/2025/03/the-path-to-an-obscure-crash/"><![CDATA[<p>One month after its first, painful release, <a href="https://passepartoutvpn.app">Passepartout</a> v3 is close to being stable.</p>

<p>However, a couple of regressions were still haunting me.</p>

<p>Here I want to describe the absurd journey into one of them, that started with a report <a href="https://github.com/passepartoutvpn/passepartout/issues/1204">from GitHub</a>, and <a href="https://www.reddit.com/r/passepartout/comments/1j0lbqa/not_open_in_sonoma_any_idea/">one from Reddit</a>. Both users were reporting that the Mac app was crashing on launch.</p>

<p>The reports led me to think that the regression was caused by the macOS version, or the CPU architecture, as both users were using an Intel-based machine.</p>

<h3 id="the-xcode-organizer">The Xcode Organizer</h3>

<p>I had several (unhelpful) crashes in the Xcode Organizer confirming the issue:</p>

<div class="h-scrolling">
    <img alt="Xcode Organizer" src="/s/posts/2025-03-03-01.png" />
</div>

<p>Looking further into some crashes, I could spot a few SIGILL (Illegal Hardware Instruction) that reinforced the idea of a platform-related issue. Add to that, one of the threads had intense Core Data + CloudKit activity ongoing. It must be Core Data, I thought, given that Passepartout performs its sync precisely when the app launches.</p>

<p><em>Doubt #1: how can the app launch at all if the arch is unsupported?</em></p>

<p><em>Doubt #2: is the Core Data stack trace relevant? Is it the thread that is actually crashing?</em></p>

<h3 id="never-read-crash-reports-only-once">Never read crash reports only once</h3>

<p>Passepartout is a privacy-oriented app. There is no external framework e.g. Firebase to help with crash resolution, so Xcode is the only technical resource at disposal. Plus the patient support from the affected users.</p>

<p>Eventually, Core Data was a distraction. Every report was crashing on “Thread 0”, i.e. the main thread. There were also crashes from macOS 15 and ARM64. Fewer, but non-zero.</p>

<p>This stack trace shed some light in that the injected AppDelegate could be the culprit. But where? And why?</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Thread 0 Crashed:
0   Passepartout                    0x00000001029bb154 0x102764000 + 2453844
1   Passepartout                    0x00000001029baf6c 0x102764000 + 2453356
2   Passepartout                    0x00000001029bb83c 0x102764000 + 2455612
3   Passepartout                    0x00000001029ba6ac 0x102764000 + 2451116
4   Passepartout                    0x00000001029b66d4 0x102764000 + 2434772
5   Passepartout                    0x000000010276d0d4 0x102764000 + 37076
6   Passepartout                    0x000000010276c868 0x102764000 + 34920
7   libdispatch.dylib               0x000000018ab68658 _dispatch_client_callout + 20 (object.m:576)
8   libdispatch.dylib               0x000000018ab69ea0 _dispatch_once_callout + 32 (once.c:52)
9   Passepartout                    0x000000010276b2ac 0x102764000 + 29356
10  Passepartout                    0x000000010276b2f0 0x102764000 + 29424
11  Passepartout                    0x000000010276b3c0 0x102764000 + 29632
12  SwiftUI                         0x00000001b977a934 FallbackDelegateBox.delegate.getter + 68 (FallbackDelegateBox.swift:36)
13  SwiftUI                         0x00000001b9e8cea8 specialized NSApplicationDelegateAdaptor.wrappedValue.getter + 156 (FallbackDelegates_Mac.swift:93)
...
</code></pre></div></div>

<h3 id="reproducing-the-crash-pt-1">Reproducing the crash (pt. 1)</h3>

<p>Assuming that the AppDelegate was doing something wrong, there was even a much bigger issue: I could not reproduce the crash on my machine. I realized, though, that a friend of mine had an Intel MacBook with macOS 14, so I asked for his help.</p>

<p>He gave me access via AnyDesk to push ad hoc builds to the machine. The latest app version crashed consistently. Off to a good start. At that point, I spent a few hours trying to exclude potentially offending parts from the launch code, sadly to no avail. Consider that any change in the code implied archiving and sending a build via AnyDesk to test it. It was exhausting, and the afternoon led nowhere.</p>

<h3 id="reproducing-the-crash-pt-2">Reproducing the crash (pt. 2)</h3>

<p>I decide to give a shot to virtualization. Most crashes came from macOS 14, and not necessarily from Intel machines, so this could work. These were the steps:</p>

<ul>
  <li>Get <a href="https://mac.getutm.app/">UTM</a> to run a VM on Mac. <em>Highly recommended!</em></li>
  <li>Download a restore image for Sonoma (~14GB)</li>
  <li>Regenerate the provisioning profile with the VM UDID</li>
  <li>Send the development build via a shared folder to the VM</li>
</ul>

<p>The app crashes. Hooray!</p>

<h3 id="git-to-the-rescue">Git to the rescue</h3>

<p>Time to locate where the regression was introduced. I rebuilt the app for each commit that sounded relevant, and after 10-20 builds, I found out that the crash was introduced in <a href="https://github.com/passepartoutvpn/passepartout/pull/1200">this pull request</a> about the light/dark mode picker in the app preferences. WTF?!</p>

<p>It turns out, the widely used <a href="https://developer.apple.com/documentation/appkit/nsapp"><code class="language-plaintext highlighter-rouge">NSApp</code> singleton</a> is an <strong>implicitly unwrapped optional</strong>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@MainActor
var NSApp: NSApplication!
</code></pre></div></div>

<p>and it was therefore used unsafely in this bit of the PR:</p>

<script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2Fpassepartoutvpn%2Fpassepartout%2Fblob%2Fv3.1.1%2FPackages%2FApp%2FSources%2FUILibrary%2FBusiness%2FAppearanceManager.swift%23L66-73&amp;style=default&amp;type=code&amp;showBorder=on&amp;showLineNumbers=on&amp;showFileMeta=on&amp;showFullPath=on&amp;showCopy=on"></script>

<h3 id="a-race-condition-about-nsapp">A race condition about NSApp</h3>

<p>It’s finally revealed that, very early in a Mac app lifecycle, <code class="language-plaintext highlighter-rouge">NSApp</code> may be nil. This was more often the case on macOS 14 than 15, but still a hideous race condition.</p>

<p>Here goes the simplified stack call:</p>

<ul>
  <li>main</li>
  <li>AppDelegate.init</li>
  <li>AppearanceManager.init</li>
  <li>AppearanceManager.systemAppearance.didSet</li>
  <li>AppearanceManager.apply()</li>
  <li>NSApp.appearance = …</li>
</ul>

<p>In the last call, <code class="language-plaintext highlighter-rouge">NSApp</code> may be nil and implicitly unwrapped, leading to the crash.</p>

<h3 id="lessons-learned">Lessons learned</h3>

<p>This was one of those bugs that make you question everything—platform differences, architecture quirks, even Core Data conspiracies—before revealing a simple yet insidious root cause: a race condition with <code class="language-plaintext highlighter-rouge">NSApp</code>.</p>

<p>The takeaway? Even well-documented singletons aren’t always safe to assume as non-nil. And when debugging obscure crashes, patience and a systematic approach (plus a good VM setup) can make all the difference.</p>

<p>Passepartout v3.1.5 <a href="https://github.com/passepartoutvpn/passepartout/pull/1224">will handle this case properly</a>, ensuring that <code class="language-plaintext highlighter-rouge">NSApp</code> is accessed only when it’s actually available. Hopefully, that’s one less obscure crash lurking in the shadows.</p>

<p>To Apple and Swift: isn’t it about time to discourage/deprecate the use of implicitly unwrapped optionals?</p>]]></content><author><name>Davide De Rosa</name></author><category term="development" /><category term="swift" /><summary type="html"><![CDATA[One month after its first, painful release, Passepartout v3 is close to being stable. However, a couple of regressions were still haunting me. Here I want to describe the absurd journey into one of them, that started with a report from GitHub, and one from Reddit. Both users were reporting that the Mac app was crashing on launch. The reports led me to think that the regression was caused by the macOS version, or the CPU architecture, as both users were using an Intel-based machine. The Xcode Organizer I had several (unhelpful) crashes in the Xcode Organizer confirming the issue: Looking further into some crashes, I could spot a few SIGILL (Illegal Hardware Instruction) that reinforced the idea of a platform-related issue. Add to that, one of the threads had intense Core Data + CloudKit activity ongoing. It must be Core Data, I thought, given that Passepartout performs its sync precisely when the app launches. Doubt #1: how can the app launch at all if the arch is unsupported? Doubt #2: is the Core Data stack trace relevant? Is it the thread that is actually crashing? Never read crash reports only once Passepartout is a privacy-oriented app. There is no external framework e.g. Firebase to help with crash resolution, so Xcode is the only technical resource at disposal. Plus the patient support from the affected users. Eventually, Core Data was a distraction. Every report was crashing on “Thread 0”, i.e. the main thread. There were also crashes from macOS 15 and ARM64. Fewer, but non-zero. This stack trace shed some light in that the injected AppDelegate could be the culprit. But where? And why? Thread 0 Crashed: 0 Passepartout 0x00000001029bb154 0x102764000 + 2453844 1 Passepartout 0x00000001029baf6c 0x102764000 + 2453356 2 Passepartout 0x00000001029bb83c 0x102764000 + 2455612 3 Passepartout 0x00000001029ba6ac 0x102764000 + 2451116 4 Passepartout 0x00000001029b66d4 0x102764000 + 2434772 5 Passepartout 0x000000010276d0d4 0x102764000 + 37076 6 Passepartout 0x000000010276c868 0x102764000 + 34920 7 libdispatch.dylib 0x000000018ab68658 _dispatch_client_callout + 20 (object.m:576) 8 libdispatch.dylib 0x000000018ab69ea0 _dispatch_once_callout + 32 (once.c:52) 9 Passepartout 0x000000010276b2ac 0x102764000 + 29356 10 Passepartout 0x000000010276b2f0 0x102764000 + 29424 11 Passepartout 0x000000010276b3c0 0x102764000 + 29632 12 SwiftUI 0x00000001b977a934 FallbackDelegateBox.delegate.getter + 68 (FallbackDelegateBox.swift:36) 13 SwiftUI 0x00000001b9e8cea8 specialized NSApplicationDelegateAdaptor.wrappedValue.getter + 156 (FallbackDelegates_Mac.swift:93) ... Reproducing the crash (pt. 1) Assuming that the AppDelegate was doing something wrong, there was even a much bigger issue: I could not reproduce the crash on my machine. I realized, though, that a friend of mine had an Intel MacBook with macOS 14, so I asked for his help. He gave me access via AnyDesk to push ad hoc builds to the machine. The latest app version crashed consistently. Off to a good start. At that point, I spent a few hours trying to exclude potentially offending parts from the launch code, sadly to no avail. Consider that any change in the code implied archiving and sending a build via AnyDesk to test it. It was exhausting, and the afternoon led nowhere. Reproducing the crash (pt. 2) I decide to give a shot to virtualization. Most crashes came from macOS 14, and not necessarily from Intel machines, so this could work. These were the steps: Get UTM to run a VM on Mac. Highly recommended! Download a restore image for Sonoma (~14GB) Regenerate the provisioning profile with the VM UDID Send the development build via a shared folder to the VM The app crashes. Hooray! Git to the rescue Time to locate where the regression was introduced. I rebuilt the app for each commit that sounded relevant, and after 10-20 builds, I found out that the crash was introduced in this pull request about the light/dark mode picker in the app preferences. WTF?! It turns out, the widely used NSApp singleton is an implicitly unwrapped optional: @MainActor var NSApp: NSApplication! and it was therefore used unsafely in this bit of the PR: A race condition about NSApp It’s finally revealed that, very early in a Mac app lifecycle, NSApp may be nil. This was more often the case on macOS 14 than 15, but still a hideous race condition. Here goes the simplified stack call: main AppDelegate.init AppearanceManager.init AppearanceManager.systemAppearance.didSet AppearanceManager.apply() NSApp.appearance = … In the last call, NSApp may be nil and implicitly unwrapped, leading to the crash. Lessons learned This was one of those bugs that make you question everything—platform differences, architecture quirks, even Core Data conspiracies—before revealing a simple yet insidious root cause: a race condition with NSApp. The takeaway? Even well-documented singletons aren’t always safe to assume as non-nil. And when debugging obscure crashes, patience and a systematic approach (plus a good VM setup) can make all the difference. Passepartout v3.1.5 will handle this case properly, ensuring that NSApp is accessed only when it’s actually available. Hopefully, that’s one less obscure crash lurking in the shadows. To Apple and Swift: isn’t it about time to discourage/deprecate the use of implicitly unwrapped optionals?]]></summary></entry><entry><title type="html">Wallet software</title><link href="https://davidederosa.com/basic-blockchain-programming/wallet-software/" rel="alternate" type="text/html" title="Wallet software" /><published>2015-06-23T00:00:00+02:00</published><updated>2015-06-23T00:00:00+02:00</updated><id>https://davidederosa.com/basic-blockchain-programming/wallet-software</id><content type="html" xml:base="https://davidederosa.com/basic-blockchain-programming/wallet-software/"><![CDATA[<p>Commonly, Bitcoin users rely on clients called <em>wallets</em> to create transactions and interact with the p2p network. Even Bitcoin Core is a wallet itself, besides being the official software for mining. Other well-known wallets are <a href="https://electrum.org">Electrum</a>, <a href="https://hivewallet.com">Hive</a> etc. Here I’ll try to describe the components of a wallet.</p>

<h3 id="data-model">Data model</h3>

<p>These are the typical data structures that a wallet maintains internally. Most of them accomplish the core business of the wallet, that is building transactions and broadcasting them to the Bitcoin network. Things like <em>change addresses</em> or encryption are convenient features yet not mandatory for a fully working implementation.</p>

<h4 id="keypairs">Keypairs</h4>

<p>In the last paragraphs about the <a href="/basic-blockchain-programming/network-interoperability-part-two/">Bitcoin network</a>, you learned how to create a primitive wallet. Given an ECDSA keypair, a basic Bitcoin wallet is made of:</p>

<ul>
  <li>The WIF-encoded private key.</li>
  <li>The Base58Check-encoded hash160 of the public key, i.e. the P2PKH address.</li>
</ul>

<p>Real wallets actually create many keypairs, but stick with a single one for the sake of simplicity. In a tiered context, the keypair is the foundation of our data model and will “hold” our coins.</p>

<h4 id="blockchain">Blockchain</h4>

<p>The blockchain component determines if a wallet is <em>thin</em> or <em>heavyweight</em>. Heavyweight wallets like Bitcoin Core are backed by a full blockchain, whereas thin wallets like Electrum and Hive only need a part of it or none at all, thus being suitable for slow connections or devices with limited capabilities like smartphones.</p>

<p>“Heavy” really means it. At the time of writing, a Bitcoin Core wallet would take about 40GB of disk space to allocate the full blockchain locally, which includes all broadcast Bitcoin transactions since the beginning of time. And increasing. Conveniently, a thin client is much faster under the assumption that a normal user is not interested in every transaction in Bitcoin history. Instead, it will only download <em>relevant</em> transactions, that is transactions in which the user appears as a sender or a receiver.</p>

<p>Focus on keypairs again. If our wallet only deals with standard P2PKH transactions –and most do–, we can safely assume that:</p>

<ol>
  <li>The user is a receiver when his address appears in a transaction output script.</li>
  <li>The user is a sender when his public key appears in a transaction input script.</li>
</ol>

<p>Let’s see why. Consider the typical P2PKH output script:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>OP_DUP
OP_HASH160
[hash160(public_key)]
OP_EQUALVERIFY
OP_CHECKSIG
</code></pre></div></div>

<p>the typical P2PKH input script:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[signature]
[public_key]
</code></pre></div></div>

<p>and the relevancy scan in pseudocode:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>outpoint = struct { txid, index };

relevant_txs = {};  /* txid -&gt; tx */
utxos = {};         /* outpoint */
balance = 0;

for (tx in blockchain.txs) {

    /* 1 */
    for (txout in tx.outputs) {
        if (!is_p2pkh_output(txout.script)) {
            continue;
        }
        if (txout.script contains hash160(keypair.public_key)) {
            relevant_txs.add(tx);

            outpoint = outpoint(tx.id, txout.index);
            utxos.add(outpoint);
            balance += txout.value;
        }
    }

    /* 2 */
    for (txin in tx.inputs) {
        if (!is_p2pkh_input(txin.script)) {
            continue;
        }
        if (txin.script contains keypair.public_key) {
            relevant_txs.add(tx);

            outpoint = txin.outpoint;
            previous_tx = relevant_txs[outpoint.txid];
            prev_txout = previous_tx.outputs[outpoint.index];
            utxos.remove(outpoint);
            balance -= prev_txout.value;
        }
    }
}
</code></pre></div></div>

<p>(1) If any P2PKH transaction output contains the hash160 of our public key –our Bitcoin address–, the transaction is relevant to our wallet. Such an output associates more coins to our wallet keypair and contributes to the <em>output value</em> of the wallet. Until it’s spent, the output is an element of the UTXO set of the wallet, therefore increasing the balance.</p>

<p>(2) If any P2PKH transaction input contains our public key, the transaction is relevant to our wallet. Such a transaction input spends coins associated with our wallet keypair, specifically it spends the output referenced by the input outpoint. The previous output is removed from the UTXO set because outputs are always spent in their entirety. After the spend, the balance decreases.</p>

<p>Incidentally, you may notice that the relevant transactions form the <em>history</em> of a wallet.</p>

<h4 id="utxos">UTXOs</h4>

<p>So, given a keypair, the two criteria dramatically cut down the search time for relevant transactions in the blockchain, be it local (heavyweight wallet) or remote (thin wallet). To build new transactions, though, we must track the UTXO set, which appears to be a bonus result of the scanning process. All transaction outputs are initially added to the UTXOs, but they’re later removed if reused in another transaction as input outpoints. The final set provides us with the available outpoints for building new transactions.</p>

<p>We can also compute the wallet balance from the UTXOs:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>balance = 0;

for (outpoint in utxos) {
    unspent_tx = relevant_txs[outpoint.txid];
    unspent_txout = unspent_tx.outputs[outpoint.index];
    balance += unspent_txout.value;
}
</code></pre></div></div>

<h3 id="modularization">Modularization</h3>

<p>From an architectural perspective, a wallet software can be split into 3 independent modules:</p>

<ol>
  <li>Signing module.</li>
  <li>Public addresses module.</li>
  <li>Networking module.</li>
</ol>

<p>Most wallets are essentially monolithic, others are hybrid in that they sign transactions in a separate module. <a href="https://www.bitcointrezor.com/">TREZOR</a> is a well-known example of hybrid wallet where the signing module is even pushed to an external device.</p>

<h4 id="signing">Signing</h4>

<p>This module is the only one holding sensitive data: the private key(s). It receives an unsigned transaction and returns a signed one, ready to be published to the Bitcoin network. Since the signing task involves just ECDSA, the module can be -and often is- conveniently implemented in hardware. This arrangement allows for strong <a href="https://en.wikipedia.org/wiki/Two-factor_authentication">2-factor authentication</a>.</p>

<p><img src="http://www.firebrick.co.uk/images/otp.jpg" alt="One-Time Password device" /></p>

<p>Think of OTP (One-Time Password) devices, those handy password generators designed to fit in your keyring. OTPs are often used for private banking to generate a login token that is only valid within a short time period. The token is the second step you take to enter your bank account after entering your credentials, and additional tokens can be requested for particularly sensitive operations. Your brain (the credentials) and the OTP device (the token) together protect the account. You won’t be able to log in in case you miss any of the two.</p>

<p><img src="https://www.bitcointrezor.com/images/carousel_4.png" alt="TREZOR signing device" /></p>

<p>Now look at the TREZOR. The TREZOR signing device is also part of a 2-factor authentication scheme, because the ability to create a transaction depends on 2 physically separate modules: the TREZOR itself (for the ECDSA keys) and a networking/blockchain software running on desktop or mobile (for the UTXOs). The device receives an unsigned transaction and signs it after manual confirmation. Then, the signed transaction is sent back to the network-connected software and finally broadcast. Again, the device alone won’t be able to build transactions because it has zero knowledge of the blockchain. Likewise, a transaction cannot be signed by the networked software as it has no access to the private keys.</p>

<h4 id="public-addresses">Public addresses</h4>

<p>Private and public keys are strongly related, still they can live in completely different contexts. In fact, they’re loosely coupled by nature. That’s why a wallet may opt for a public addresses distribution module. However, in our single keypair scenario such a module would be overkill, because we would be distributing just one public address.</p>

<p>Public-key distribution would only make sense after learning about <a href="https://codinginmysleep.com/hd-wallets-in-plain-english/">deterministic wallets</a>, which I won’t deal with in this series. Plus, most wallets have this module conveniently merged into the networking component, since public addresses need to be constantly monitored for incoming transactions.</p>

<h4 id="networking">Networking</h4>

<p>The networking module would sit in the middle of the other two, and it’s also the controller module. It’s in charge of several, sometimes complicated tasks:</p>

<ol>
  <li>Connecting to the Bitcoin p2p network.</li>
  <li>Synchronizing and keeping up with the blockchain.</li>
  <li>Monitoring relevant transactions.</li>
  <li>Publishing transactions.</li>
</ol>

<p>Especially task 1 and 2 can be a <a href="https://www.urbandictionary.com/define.php?term=pita">PITA</a>, look at the vague protocol description for <a href="https://en.bitcoin.it/wiki/Block_chain_download">blockchain download</a>. It’s no surprise that many wallet manifacturers -like <a href="https://electrum.org">Electrum</a> and <a href="https://mycelium.com">Mycelium</a>- have chosen to set up their own centralized synchronization network. Thin wallets are severely affected by the overwhelming complexity of blockchain synchronization.</p>

<p>Task 3 is described in the above paragraph about the blockchain model, and requires the knowledge of the public key of our keypair. With the public key we’re able to monitor/restore both incoming and outcoming P2PKH transactions. Most importantly, the relevant transactions history determines the UTXO set of the wallet, which we’ll need to build new transactions.</p>

<p>Task 4 is definitely the easiest, unless a wallet is advanced enough to pick the best UTXOs according to <a href="https://bitcoin.stackexchange.com/questions/1077/what-is-the-coin-selection-algorithm">coin selection heuristics</a>. After gathering the UTXOs and composing the unsigned transaction, it’s transmitted to the signing module. The unsigned transaction is signed and returned to the networking module, which in turn announces it to the Bitcoin network. Finally, it waits for the transaction to be mined in the upcoming blocks of the blockchain.</p>

<h3 id="goodbye">Goodbye!</h3>

<p>That’s all. From now on, you should be <em>way</em> more comfortable with how Bitcoin works under the hood. Of course there’s much more to uncover, so I’m particularly interested in what topics you’d love to know more about. That’s why your feedback is golden, let me know in the comments what you enjoyed or didn’t about this series.</p>

<p>This is free work and I won’t explicitly beg for donations. I’d rather be glad if you take your time to spread the word and share these articles with your friends or on social networks. After all, Bitcoin is far from being mainstream and significantly counts on word of mouth.</p>

<p>And remember, all the code is on my <a href="https://github.com/keeshux/basic-blockchain-programming/">GitHub repository</a>.</p>

<p>Keep mining!</p>]]></content><author><name>Davide De Rosa</name></author><category term="bitcoin" /><category term="bitcoin" /><category term="blockchain" /><category term="programming" /><category term="development" /><category term="wallet" /><category term="ecdsa" /><category term="thin client" /><category term="utxo" /><summary type="html"><![CDATA[Commonly, Bitcoin users rely on clients called wallets to create transactions and interact with the p2p network. Even Bitcoin Core is a wallet itself, besides being the official software for mining. Other well-known wallets are Electrum, Hive etc. Here I’ll try to describe the components of a wallet. Data model These are the typical data structures that a wallet maintains internally. Most of them accomplish the core business of the wallet, that is building transactions and broadcasting them to the Bitcoin network. Things like change addresses or encryption are convenient features yet not mandatory for a fully working implementation. Keypairs In the last paragraphs about the Bitcoin network, you learned how to create a primitive wallet. Given an ECDSA keypair, a basic Bitcoin wallet is made of: The WIF-encoded private key. The Base58Check-encoded hash160 of the public key, i.e. the P2PKH address. Real wallets actually create many keypairs, but stick with a single one for the sake of simplicity. In a tiered context, the keypair is the foundation of our data model and will “hold” our coins. Blockchain The blockchain component determines if a wallet is thin or heavyweight. Heavyweight wallets like Bitcoin Core are backed by a full blockchain, whereas thin wallets like Electrum and Hive only need a part of it or none at all, thus being suitable for slow connections or devices with limited capabilities like smartphones. “Heavy” really means it. At the time of writing, a Bitcoin Core wallet would take about 40GB of disk space to allocate the full blockchain locally, which includes all broadcast Bitcoin transactions since the beginning of time. And increasing. Conveniently, a thin client is much faster under the assumption that a normal user is not interested in every transaction in Bitcoin history. Instead, it will only download relevant transactions, that is transactions in which the user appears as a sender or a receiver. Focus on keypairs again. If our wallet only deals with standard P2PKH transactions –and most do–, we can safely assume that: The user is a receiver when his address appears in a transaction output script. The user is a sender when his public key appears in a transaction input script. Let’s see why. Consider the typical P2PKH output script: OP_DUP OP_HASH160 [hash160(public_key)] OP_EQUALVERIFY OP_CHECKSIG the typical P2PKH input script: [signature] [public_key] and the relevancy scan in pseudocode: outpoint = struct { txid, index }; relevant_txs = {}; /* txid -&gt; tx */ utxos = {}; /* outpoint */ balance = 0; for (tx in blockchain.txs) { /* 1 */ for (txout in tx.outputs) { if (!is_p2pkh_output(txout.script)) { continue; } if (txout.script contains hash160(keypair.public_key)) { relevant_txs.add(tx); outpoint = outpoint(tx.id, txout.index); utxos.add(outpoint); balance += txout.value; } } /* 2 */ for (txin in tx.inputs) { if (!is_p2pkh_input(txin.script)) { continue; } if (txin.script contains keypair.public_key) { relevant_txs.add(tx); outpoint = txin.outpoint; previous_tx = relevant_txs[outpoint.txid]; prev_txout = previous_tx.outputs[outpoint.index]; utxos.remove(outpoint); balance -= prev_txout.value; } } } (1) If any P2PKH transaction output contains the hash160 of our public key –our Bitcoin address–, the transaction is relevant to our wallet. Such an output associates more coins to our wallet keypair and contributes to the output value of the wallet. Until it’s spent, the output is an element of the UTXO set of the wallet, therefore increasing the balance. (2) If any P2PKH transaction input contains our public key, the transaction is relevant to our wallet. Such a transaction input spends coins associated with our wallet keypair, specifically it spends the output referenced by the input outpoint. The previous output is removed from the UTXO set because outputs are always spent in their entirety. After the spend, the balance decreases. Incidentally, you may notice that the relevant transactions form the history of a wallet. UTXOs So, given a keypair, the two criteria dramatically cut down the search time for relevant transactions in the blockchain, be it local (heavyweight wallet) or remote (thin wallet). To build new transactions, though, we must track the UTXO set, which appears to be a bonus result of the scanning process. All transaction outputs are initially added to the UTXOs, but they’re later removed if reused in another transaction as input outpoints. The final set provides us with the available outpoints for building new transactions. We can also compute the wallet balance from the UTXOs: balance = 0; for (outpoint in utxos) { unspent_tx = relevant_txs[outpoint.txid]; unspent_txout = unspent_tx.outputs[outpoint.index]; balance += unspent_txout.value; } Modularization From an architectural perspective, a wallet software can be split into 3 independent modules: Signing module. Public addresses module. Networking module. Most wallets are essentially monolithic, others are hybrid in that they sign transactions in a separate module. TREZOR is a well-known example of hybrid wallet where the signing module is even pushed to an external device. Signing This module is the only one holding sensitive data: the private key(s). It receives an unsigned transaction and returns a signed one, ready to be published to the Bitcoin network. Since the signing task involves just ECDSA, the module can be -and often is- conveniently implemented in hardware. This arrangement allows for strong 2-factor authentication. Think of OTP (One-Time Password) devices, those handy password generators designed to fit in your keyring. OTPs are often used for private banking to generate a login token that is only valid within a short time period. The token is the second step you take to enter your bank account after entering your credentials, and additional tokens can be requested for particularly sensitive operations. Your brain (the credentials) and the OTP device (the token) together protect the account. You won’t be able to log in in case you miss any of the two. Now look at the TREZOR. The TREZOR signing device is also part of a 2-factor authentication scheme, because the ability to create a transaction depends on 2 physically separate modules: the TREZOR itself (for the ECDSA keys) and a networking/blockchain software running on desktop or mobile (for the UTXOs). The device receives an unsigned transaction and signs it after manual confirmation. Then, the signed transaction is sent back to the network-connected software and finally broadcast. Again, the device alone won’t be able to build transactions because it has zero knowledge of the blockchain. Likewise, a transaction cannot be signed by the networked software as it has no access to the private keys. Public addresses Private and public keys are strongly related, still they can live in completely different contexts. In fact, they’re loosely coupled by nature. That’s why a wallet may opt for a public addresses distribution module. However, in our single keypair scenario such a module would be overkill, because we would be distributing just one public address. Public-key distribution would only make sense after learning about deterministic wallets, which I won’t deal with in this series. Plus, most wallets have this module conveniently merged into the networking component, since public addresses need to be constantly monitored for incoming transactions. Networking The networking module would sit in the middle of the other two, and it’s also the controller module. It’s in charge of several, sometimes complicated tasks: Connecting to the Bitcoin p2p network. Synchronizing and keeping up with the blockchain. Monitoring relevant transactions. Publishing transactions. Especially task 1 and 2 can be a PITA, look at the vague protocol description for blockchain download. It’s no surprise that many wallet manifacturers -like Electrum and Mycelium- have chosen to set up their own centralized synchronization network. Thin wallets are severely affected by the overwhelming complexity of blockchain synchronization. Task 3 is described in the above paragraph about the blockchain model, and requires the knowledge of the public key of our keypair. With the public key we’re able to monitor/restore both incoming and outcoming P2PKH transactions. Most importantly, the relevant transactions history determines the UTXO set of the wallet, which we’ll need to build new transactions. Task 4 is definitely the easiest, unless a wallet is advanced enough to pick the best UTXOs according to coin selection heuristics. After gathering the UTXOs and composing the unsigned transaction, it’s transmitted to the signing module. The unsigned transaction is signed and returned to the networking module, which in turn announces it to the Bitcoin network. Finally, it waits for the transaction to be mined in the upcoming blocks of the blockchain. Goodbye! That’s all. From now on, you should be way more comfortable with how Bitcoin works under the hood. Of course there’s much more to uncover, so I’m particularly interested in what topics you’d love to know more about. That’s why your feedback is golden, let me know in the comments what you enjoyed or didn’t about this series. This is free work and I won’t explicitly beg for donations. I’d rather be glad if you take your time to spread the word and share these articles with your friends or on social networks. After all, Bitcoin is far from being mainstream and significantly counts on word of mouth. And remember, all the code is on my GitHub repository. Keep mining!]]></summary></entry><entry><title type="html">The first transaction (pt. 2)</title><link href="https://davidederosa.com/basic-blockchain-programming/the-first-transaction-part-two/" rel="alternate" type="text/html" title="The first transaction (pt. 2)" /><published>2015-06-03T00:00:00+02:00</published><updated>2015-06-03T00:00:00+02:00</updated><id>https://davidederosa.com/basic-blockchain-programming/the-first-transaction-part-two</id><content type="html" xml:base="https://davidederosa.com/basic-blockchain-programming/the-first-transaction-part-two/"><![CDATA[<p>The <a href="/basic-blockchain-programming/the-first-transaction-part-one/">first part</a> covered the basics of transaction building, like creating outputs from the destination addresses and gathering the needed input value. The most complicated part was constructing a message for the input signature. Now that we have one, we’re going to generate a signature and finally a script for the transaction input. The last step is about packing all the stuff together.</p>

<!--more-->

<h3 id="the-input-script">The input script</h3>

<p>As a result of <a href="https://github.com/keeshux/basic-blockchain-programming/blob/master/ex-tx-build.c">ex-tx-build.c</a>, we built the signable message for our input. In <a href="https://github.com/keeshux/basic-blockchain-programming/blob/master/ex-tx-sign.c">ex-tx-sign.c</a> we’ll reuse the message as a starting point.</p>

<h4 id="producing-the-signature">Producing the signature</h4>

<p>Rather than the message itself, we’ll sign its hash256 digest:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>62 44 98 0f a0 75 2e 5b
46 43 ed b3 53 fd a5 23
8a 9a 3d 44 49 16 76 78
8e fd d2 5d d6 48 55 ba
</code></pre></div></div>

<p>with our <a href="https://github.com/keeshux/basic-blockchain-programming/blob/master/ec-priv.pem">ECDSA private key</a>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>16 26 07 83 e4 0b 16 73
16 73 62 2a c8 a5 b0 45
fc 3e a4 af 70 f7 27 f3
f9 e9 2b dd 3a 1d dc 42
</code></pre></div></div>

<p>This is one DER signature I yielded (yours will differ):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>30 44 02 20 11 1a 48 2a
ba 6a fb a1 2a 6f 27 de
76 7d d4 d0 64 17 de f6
65 bd 10 0b c6 8c 42 84
5c 75 2a 8f 02 20 5e 86
f5 e0 54 b2 c6 ca c5 d6
63 66 4e 35 77 9f b0 34
38 7c 07 84 8b c7 72 44
42 ca cf 65 93 24 
</code></pre></div></div>

<h4 id="flag-and-assembly">Flag and assembly</h4>

<p>The <code class="language-plaintext highlighter-rouge">SIGHASH</code> flag (now 8-bit) is appended again to the signature, and together with the compressed <a href="https://github.com/keeshux/basic-blockchain-programming/blob/master/ec-pub.pem">ECDSA public key</a>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>02
82 00 6e 93 98 a6 98 6e
da 61 fe 91 67 4c 3a 10
8c 39 94 75 bf 1e 73 8f
19 df c2 db 11 db 1d 28
</code></pre></div></div>

<p>we’re finally able to build our P2PKH input script:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>47 30 44 02 20 11 1a 48
2a ba 6a fb a1 2a 6f 27
de 76 7d d4 d0 64 17 de
f6 65 bd 10 0b c6 8c 42
84 5c 75 2a 8f 02 20 5e
86 f5 e0 54 b2 c6 ca c5
d6 63 66 4e 35 77 9f b0
34 38 7c 07 84 8b c7 72
44 42 ca cf 65 93 24 01

21 02 82 00 6e 93 98 a6
98 6e da 61 fe 91 67 4c
3a 10 8c 39 94 75 bf 1e
73 8f 19 df c2 db 11 db
1d 28
</code></pre></div></div>

<p>Yes, the signing process is possibly the most annoying and error-prone part of our work.</p>

<h3 id="packing-the-transaction">Packing the transaction</h3>

<p>We’re all set to pack the transaction from our inputs and outputs. Let’s look at <a href="https://github.com/keeshux/basic-blockchain-programming/blob/master/ex-tx-pack.c">ex-tx-pack.c</a>.</p>

<h4 id="inputs-and-outputs">Inputs and outputs</h4>

<p>Like I did for outputs, I also wrote a C macro in <a href="https://github.com/keeshux/basic-blockchain-programming/blob/master/tx.h">tx.h</a> for creating P2PKH inputs. The macro takes an UTXO outpoint, a signature, a public key and a <code class="language-plaintext highlighter-rouge">SIGHASH</code> flag:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="kt">void</span> <span class="nf">bbp_txin_create_p2pkh</span><span class="p">(</span><span class="n">bbp_txin_t</span> <span class="o">*</span><span class="n">txin</span><span class="p">,</span> <span class="k">const</span> <span class="n">bbp_outpoint_t</span> <span class="o">*</span><span class="n">outpoint</span><span class="p">,</span>
        <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">sig</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span> <span class="o">*</span><span class="n">pub</span><span class="p">,</span> <span class="n">bbp_sighash_t</span> <span class="n">flag</span><span class="p">);</span></code></pre></figure>

<p>We use the macro to create our input, whereas the outputs code is taken from <a href="https://github.com/keeshux/basic-blockchain-programming/blob/master/ex-tx-build.c">ex-tx-build.c</a> as is:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="n">bbp_outpoint_fill</span><span class="p">(</span><span class="o">&amp;</span><span class="n">outpoint</span><span class="p">,</span>
        <span class="s">"f34e1c37e736727770fed85d1b129713ef7f300304498c31c833985f487fa2f3"</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
<span class="n">bbp_txin_create_p2pkh</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ins</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">&amp;</span><span class="n">outpoint</span><span class="p">,</span>
        <span class="s">"30440220111a482aba6afba12a6f27de767dd4d06..."</span><span class="p">,</span>
        <span class="s">"0282006e9398a6986eda61fe91674c3a108c39947..."</span><span class="p">,</span>
        <span class="n">BBP_SIGHASH_ALL</span><span class="p">);</span>

<span class="n">bbp_txout_create_p2pkh</span><span class="p">(</span><span class="o">&amp;</span><span class="n">outs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">25100000</span><span class="p">,</span>
        <span class="s">"18ba14b3682295cb05230e31fecb000892406608"</span><span class="p">);</span>
<span class="n">bbp_txout_create_p2pkh</span><span class="p">(</span><span class="o">&amp;</span><span class="n">outs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">61900000</span><span class="p">,</span>
        <span class="s">"6bf19e55f94d986b4640c154d864699341919511"</span><span class="p">);</span></code></pre></figure>

<h4 id="final-structure">Final structure</h4>

<p>The easiest step is assembling the transaction structure and feeding it to <code class="language-plaintext highlighter-rouge">bbp_tx_serialize</code>:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="n">tx</span><span class="p">.</span><span class="n">version</span> <span class="o">=</span> <span class="n">bbp_eint32</span><span class="p">(</span><span class="n">BBP_LITTLE</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
<span class="n">tx</span><span class="p">.</span><span class="n">outputs_len</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
<span class="n">tx</span><span class="p">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="n">outs</span><span class="p">;</span>
<span class="n">tx</span><span class="p">.</span><span class="n">inputs_len</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="n">tx</span><span class="p">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ins</span><span class="p">;</span>
<span class="n">tx</span><span class="p">.</span><span class="n">locktime</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="n">rawtx_len</span> <span class="o">=</span> <span class="n">bbp_tx_size</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tx</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
<span class="n">rawtx</span> <span class="o">=</span> <span class="n">malloc</span><span class="p">(</span><span class="n">rawtx_len</span><span class="p">);</span>
<span class="n">bbp_tx_serialize</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tx</span><span class="p">,</span> <span class="n">rawtx</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span></code></pre></figure>

<p>The <code class="language-plaintext highlighter-rouge">flag</code> parameter is set to <code class="language-plaintext highlighter-rouge">0</code> to pack a signed transaction instead of a signable message. The serialized transaction is:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/* version (32-bit) */
01 00 00 00

/* number of inputs (varint) */
01

/* UTXO txid (hash256, little-endian) */
f3 a2 7f 48 5f 98 33 c8
31 8c 49 04 03 30 7f ef
13 97 12 1b 5d d8 fe 70
77 72 36 e7 37 1c 4e f3

/* UTXO index (32-bit) */
00 00 00 00

/* input script (varint + data) */
6a 47 30 44 02 20 11 1a
48 2a ba 6a fb a1 2a 6f
27 de 76 7d d4 d0 64 17
de f6 65 bd 10 0b c6 8c
42 84 5c 75 2a 8f 02 20
5e 86 f5 e0 54 b2 c6 ca
c5 d6 63 66 4e 35 77 9f
b0 34 38 7c 07 84 8b c7
72 44 42 ca cf 65 93 24
01 21 02 82 00 6e 93 98
a6 98 6e da 61 fe 91 67
4c 3a 10 8c 39 94 75 bf
1e 73 8f 19 df c2 db 11
db 1d 28 

/* UTXO sequence */
ff ff ff ff

/* number of outputs (varint) */
02

/* output value (64-bit) */
e0 fe 7e 01 00 00 00 00

/* output script (varint + data) */
19 76 a9 14 18 ba 14 b3
68 22 95 cb 05 23 0e 31
fe cb 00 08 92 40 66 08
88 ac

/* change output value (64-bit) */
e0 84 b0 03 00 00 00 00

/* change output script (varint + data) */
19 76 a9 14 6b f1 9e 55
f9 4d 98 6b 46 40 c1 54
d8 64 69 93 41 91 95 11
88 ac

/* locktime (32-bit) */
00 00 00 00
</code></pre></div></div>

<p>and measures 225 bytes. The txid is obtained by performing hash256 on the transaction (big-endian):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>99 96 e2 f6 4b 6a f0 23
2d d9 c8 97 39 5c e5 1f
dd 35 e6 35 9e dd 28 55
c6 0f f8 23 d8 d6 57 d1 
</code></pre></div></div>

<h4 id="publishing-to-the-network">Publishing to the network</h4>

<p>We made it, we’ve just built our first Bitcoin transaction! What’s next? Of course we want to commit our transaction to the blockchain. To do that, web services exist to save us the burden of communicating with the p2p network.</p>

<p>For example, the <a href="https://tbtc.blockr.io/tx/push">Blockr push service</a> (Testnet in our scenario) comes handy to publish raw transactions to the blockchain. Insert a raw transaction like the <code class="language-plaintext highlighter-rouge">rawtx</code> output from <a href="https://github.com/keeshux/basic-blockchain-programming/blob/master/ex-tx-pack.c">ex-tx-pack.c</a> and you’re done, you can even double-check it before confirming. If you didn’t double-spend any of your UTXOs before and you’ve done everything correctly, you should see the transaction live after a few minutes. That is, as soon as it’s mined in a block.</p>

<p>However, if you try to publish our sample transaction, you’ll get the following error:</p>

<p><img src="/s/f/basic-blockchain-programming/tx-push-error.png" alt="Transaction push error" /></p>

<p>Don’t worry, that’s because I already published it by myself. See how it looks like <a href="https://blockstream.info/testnet/tx/9996e2f64b6af0232dd9c897395ce51fdd35e6359edd2855c60ff823d8d657d1">on a block explorer</a>.</p>

<h3 id="get-the-code">Get the code!</h3>

<p>Full source on <a href="https://github.com/keeshux/basic-blockchain-programming/">GitHub</a>.</p>

<h3 id="next-block-in-chain">Next block in chain?</h3>

<p>You learned how to sign transaction inputs and pack a raw blockchain transaction. The transaction identifier (txid) is the hash256 digest of the transaction bytes.</p>

<p>In the <a href="/basic-blockchain-programming/wallet-software/">next article</a> we’ll have a look at <em>wallet software</em>. Please share this post if you enjoyed it and use the form below for questions and comments!</p>]]></content><author><name>Davide De Rosa</name></author><category term="bitcoin" /><category term="bitcoin" /><category term="blockchain" /><category term="programming" /><category term="development" /><category term="transaction" /><category term="p2pkh" /><category term="utxo" /><category term="outpoint" /><category term="script" /><category term="hashing" /><category term="ecdsa" /><summary type="html"><![CDATA[The first part covered the basics of transaction building, like creating outputs from the destination addresses and gathering the needed input value. The most complicated part was constructing a message for the input signature. Now that we have one, we’re going to generate a signature and finally a script for the transaction input. The last step is about packing all the stuff together.]]></summary></entry></feed>